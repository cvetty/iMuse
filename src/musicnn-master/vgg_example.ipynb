{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg example: use it as music feature extractor\n",
    "\n",
    "### vgg pre-trained models can be used for transfer learning or as feature extractors\n",
    "\n",
    "---------------\n",
    "\n",
    "This notebook explains how to use the vgg models in `musicnn` as music feature extractors. `musicnn` allows you to extract features at every layer of the model. For this reason, we first present it – so that you can understand what to expect out of each layer. To start, let's consider this music clip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './audio/TRWJAZW128F42760DD_test.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these two lines of code to extract music features with our vgg model trained with the [MagnaTagATune](https://github.com/keunwoochoi/magnatagatune-list) dataset – the `MTT_vgg` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:195: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn_input = tf.compat.v1.layers.batch_normalization(input_layer, training=is_training)\n",
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:197: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv1 = tf.compat.v1.layers.conv2d(inputs=bn_input,\n",
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:575: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:203: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn_conv1 = tf.compat.v1.layers.batch_normalization(conv1, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:204: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  pool1 = tf.compat.v1.layers.max_pooling2d(inputs=bn_conv1, pool_size=[4, 1], strides=[2, 2])\n",
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\keras\\legacy_tf_layers\\pooling.py:600: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:206: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  do_pool1 = tf.compat.v1.layers.dropout(pool1, rate=0.25, training=is_training)\n",
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:413: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:207: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv2 = tf.compat.v1.layers.conv2d(inputs=do_pool1,\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:213: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn_conv2 = tf.compat.v1.layers.batch_normalization(conv2, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:214: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  pool2 = tf.compat.v1.layers.max_pooling2d(inputs=bn_conv2, pool_size=[2, 2], strides=[2, 2])\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:216: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  do_pool2 = tf.compat.v1.layers.dropout(pool2, rate=0.25, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:217: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv3 = tf.compat.v1.layers.conv2d(inputs=do_pool2,\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:223: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn_conv3 = tf.compat.v1.layers.batch_normalization(conv3, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:224: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  pool3 = tf.compat.v1.layers.max_pooling2d(inputs=bn_conv3, pool_size=[2, 2], strides=[2, 2])\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:226: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  do_pool3 = tf.compat.v1.layers.dropout(pool3, rate=0.25, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:227: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv4 = tf.compat.v1.layers.conv2d(inputs=do_pool3,\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:233: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn_conv4 = tf.compat.v1.layers.batch_normalization(conv4, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:234: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  pool4 = tf.compat.v1.layers.max_pooling2d(inputs=bn_conv4, pool_size=[2, 2], strides=[2, 2])\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:236: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  do_pool4 = tf.compat.v1.layers.dropout(pool4, rate=0.25, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:237: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv5 = tf.compat.v1.layers.conv2d(inputs=do_pool4,\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:243: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn_conv5 = tf.compat.v1.layers.batch_normalization(conv5, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:244: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  pool5 = tf.compat.v1.layers.max_pooling2d(inputs=bn_conv5, pool_size=[4, 4], strides=[4, 4])\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:246: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  flat_pool5 = tf.compat.v1.layers.flatten(pool5)\n",
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:247: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  do_pool5 = tf.compat.v1.layers.dropout(flat_pool5, rate=0.5, training=is_training)\n",
      "D:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\models.py:248: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  output = tf.compat.v1.layers.dense(inputs=do_pool5,\n",
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing spectrogram (w/ librosa) and tags (w/ tensorflow).. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\librosa\\core\\audio.py:155\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\soundfile.py:629\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    628\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\soundfile.py:1183\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m-> 1183\u001b[0m \u001b[43m_error_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_snd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msf_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_ptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError opening \u001b[39;49m\u001b[38;5;132;43;01m{0!r}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\soundfile.py:1357\u001b[0m, in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1356\u001b[0m err_str \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error_number(err)\n\u001b[1;32m-> 1357\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(prefix \u001b[38;5;241m+\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mstring(err_str)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening './audio/TRWJAZW128F42760DD_test.mp3': File contains data in an unknown format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusicnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extractor\n\u001b[1;32m----> 2\u001b[0m taggram, tags, features \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMTT_vgg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\extractor.py:158\u001b[0m, in \u001b[0;36mextractor\u001b[1;34m(file_name, model, input_length, input_overlap, extract_features)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# batching data\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing spectrogram (w/ librosa) and tags (w/ tensorflow)..\u001b[39m\u001b[38;5;124m'\u001b[39m, end \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m batch, spectrogram \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# tensorflow: extract features and tags\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# ..first batch!\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_features:\n",
      "File \u001b[1;32mD:\\Projects\\SCHOOL\\IMuse\\src\\musicnn-master\\musicnn\\extractor.py:41\u001b[0m, in \u001b[0;36mbatch_data\u001b[1;34m(audio_file, n_frames, overlap)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m'''For an efficient computation, we split the full music spectrograms in patches of length n_frames with overlap.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mINPUT\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mData format: 2D np.array (time, frequency)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# compute the log-mel spectrogram with librosa\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m audio, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m audio_rep \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmelspectrogram(y\u001b[38;5;241m=\u001b[39maudio, \n\u001b[0;32m     43\u001b[0m                                            sr\u001b[38;5;241m=\u001b[39msr,\n\u001b[0;32m     44\u001b[0m                                            hop_length\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mFFT_HOP,\n\u001b[0;32m     45\u001b[0m                                            n_fft\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mFFT_SIZE,\n\u001b[0;32m     46\u001b[0m                                            n_mels\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mN_MELS)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     47\u001b[0m audio_rep \u001b[38;5;241m=\u001b[39m audio_rep\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat16)\n",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\librosa\\core\\audio.py:174\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    173\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m (exc)\n",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\librosa\\core\\audio.py:198\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"Load an audio buffer using audioread.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03mThis loads one block at a time, and then concatenates the results.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    199\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n\u001b[0;32m    200\u001b[0m     n_channels \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39mchannels\n",
      "File \u001b[1;32md:\\projects\\school\\imuse\\venv\\lib\\site-packages\\audioread\\__init__.py:116\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# All backends failed!\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m NoBackendError()\n",
      "\u001b[1;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from musicnn.extractor import extractor\n",
    "taggram, tags, features = extractor(file_name, model='MTT_vgg', extract_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the extractor, we get the **output** of the model (the `taggram` and its associated `tags`) and all the **intermediate representations** of it (we refer to those as `features`). The `features` are packed in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(features.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These different key-features correspond to the outputs of the different layers that our vgg model has. For this reason, it is important that you understand the basic bulding blocks of this model – that we briefly outline in the following diagram:\n",
    "\n",
    "<br>\n",
    "<img src=\"./images/vgg.png\">\n",
    "<br>\n",
    "\n",
    "All CNN layers (convolutional neural networks) use *same* padding, and all the max-pooling layers use a stride of 2x2 (except for the last max-pooling layer that uses a striding of 4x4).\n",
    "\n",
    "--------------------\n",
    "### How do VGG features look like?\n",
    "\n",
    "They are 3D feature tensors, with dimensions standing for (time, frequency, #filters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['pool1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['pool2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['pool3'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['pool4'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['pool5'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that `pool5` features are 2D!  \n",
    "\n",
    "This is because all the max-pooling operators have summarized the frequency content into a single value: (18, **1**, 128).  \n",
    "\n",
    "For simplicity, instead, we return a 2D representation: (18, 128).\n",
    "\n",
    "After checking the shape of these tensors, let's depict how these `MTT_vgg` features look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "\n",
    "def depict_features(features, coordinates, title, aspect='auto', xlabel=True, fontsize=13):\n",
    "    # plot features in coordinates\n",
    "    ax = plt.subplot(coordinates) \n",
    "    plt.imshow(features.T, interpolation=None, aspect=aspect)\n",
    "    # set title\n",
    "    ax.title.set_text(title + ' (' + str(features.shape[1]) + ')' )\n",
    "    ax.title.set_fontsize(fontsize)\n",
    "    # y-axis\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # x-axis\n",
    "    x_label = np.arange(0, features.shape[0], features.shape[0]//5)\n",
    "    ax.set_xticks(x_label)\n",
    "    ax.set_xticklabels(x_label, fontsize=fontsize)\n",
    "    if xlabel:\n",
    "        ax.set_xlabel('(time)', fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize pool1 features!\n",
    "gs = gridspec.GridSpec(3, 2) # create a figure having 2 rows and 3 cols.\n",
    "\n",
    "depict_features(features=features['pool1'][:,:,0],\n",
    "                coordinates=gs[0, 0],\n",
    "                title='pool1: feature #0',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool1'][:,:,35],\n",
    "                coordinates=gs[1, 0],\n",
    "                title='pool1: feature #35',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool1'][:,:,111],\n",
    "                coordinates=gs[2, 0],\n",
    "                title='pool1: feature #111',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool1'][:,:,3],\n",
    "                coordinates=gs[0, 1],\n",
    "                title='pool1: feature #3',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool1'][:,:,39],\n",
    "                coordinates=gs[1, 1],\n",
    "                title='pool1: feature #39',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool1'][:,:,101],\n",
    "                coordinates=gs[2, 1],\n",
    "                title='pool1: feature #101',\n",
    "                xlabel=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Note that we have only depicted 6 (out of 128) feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize pool2 features!\n",
    "gs = gridspec.GridSpec(3, 2) # create a figure having 2 rows and 3 cols.\n",
    "\n",
    "depict_features(features=features['pool2'][:,:,10],\n",
    "                coordinates=gs[0, 0],\n",
    "                title='pool2: feature #10',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool2'][:,:,5],\n",
    "                coordinates=gs[1, 0],\n",
    "                title='pool2: feature #5',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool2'][:,:,121],\n",
    "                coordinates=gs[2, 0],\n",
    "                title='pool2: feature #121',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool2'][:,:,33],\n",
    "                coordinates=gs[0, 1],\n",
    "                title='pool2: feature #33',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool2'][:,:,59],\n",
    "                coordinates=gs[1, 1],\n",
    "                title='pool2: feature #59',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool2'][:,:,100],\n",
    "                coordinates=gs[2, 1],\n",
    "                title='pool2: feature #100',\n",
    "                xlabel=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Note that we have only depicted 6 (out of 128) feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize pool3 features!\n",
    "gs = gridspec.GridSpec(3, 2) # create a figure having 2 rows and 3 cols.\n",
    "\n",
    "depict_features(features=features['pool3'][:,:,100],\n",
    "                coordinates=gs[0, 0],\n",
    "                title='pool3: feature #100',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool3'][:,:,50],\n",
    "                coordinates=gs[1, 0],\n",
    "                title='pool3: feature #50',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool3'][:,:,122],\n",
    "                coordinates=gs[2, 0],\n",
    "                title='pool3: feature #122',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool3'][:,:,83],\n",
    "                coordinates=gs[0, 1],\n",
    "                title='pool3: feature #83',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool3'][:,:,9],\n",
    "                coordinates=gs[1, 1],\n",
    "                title='pool3: feature #9',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool3'][:,:,104],\n",
    "                coordinates=gs[2, 1],\n",
    "                title='pool3: feature #104',\n",
    "                xlabel=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Note that we have only depicted 6 (out of 128) feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize pool4 features!\n",
    "gs = gridspec.GridSpec(3, 2) # create a figure having 2 rows and 3 cols.\n",
    "\n",
    "depict_features(features=features['pool4'][:,:,108],\n",
    "                coordinates=gs[0, 0],\n",
    "                title='pool4: feature #108',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool4'][:,:,58],\n",
    "                coordinates=gs[1, 0],\n",
    "                title='pool4: feature #58',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool4'][:,:,21],\n",
    "                coordinates=gs[2, 0],\n",
    "                title='pool4: feature #21',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool4'][:,:,23],\n",
    "                coordinates=gs[0, 1],\n",
    "                title='pool4: feature #23',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool4'][:,:,89],\n",
    "                coordinates=gs[1, 1],\n",
    "                title='pool4: feature #89',\n",
    "                xlabel=False)\n",
    "\n",
    "depict_features(features=features['pool4'][:,:,67],\n",
    "                coordinates=gs[2, 1],\n",
    "                title='pool4: feature #67',\n",
    "                xlabel=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Note that we have only depicted 6 (out of 128) feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize pool5 features!\n",
    "gs = gridspec.GridSpec(1, 1) # create a figure having 1 rows and 1 cols.\n",
    "\n",
    "depict_features(features=features['pool5'],\n",
    "                coordinates=gs[0, 0],\n",
    "                title='pool5 features',\n",
    "                xlabel=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Note that we are depicting all `pool5` features, that are 2D.\n",
    "\n",
    "----------------\n",
    "### How does the output taggram look like?\n",
    "\n",
    "By default, the model takes inputs of 3 seconds (with no overlap). Out of these 3 sec audio-patches, the model estimates the likelihood of the tags. Accordingly, the temporal resolution of the taggran is of 3 seconds.\n",
    "\n",
    "To conclude, let's visualize the `taggram` output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_length = 3 # seconds -- by default, the model takes inputs of 3 seconds with no overlap\n",
    "\n",
    "# depict taggram\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "fontsize=12\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(taggram.T, interpolation=None, aspect=\"auto\")\n",
    "\n",
    "# title\n",
    "ax.title.set_text('Taggram')\n",
    "ax.title.set_fontsize(fontsize)\n",
    "\n",
    "# x-axis title\n",
    "ax.set_xlabel('(seconds)', fontsize=fontsize)\n",
    "\n",
    "# y-axis\n",
    "y_pos = np.arange(len(tags))\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(tags, fontsize=fontsize-1)\n",
    "\n",
    "# x-axis\n",
    "x_pos = np.arange(taggram.shape[0])\n",
    "x_label = np.arange(in_length/2, in_length*taggram.shape[0], 3)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(x_label, fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
