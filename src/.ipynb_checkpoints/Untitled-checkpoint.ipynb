{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1688d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, Reshape, Permute, ReLU, Input, MaxPool1D, Conv1D, Conv2D, Dense, MaxPooling2D, GlobalMaxPooling2D, UpSampling2D, Concatenate\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44cde09",
   "metadata": {},
   "source": [
    "### VGGish model TF2 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76bdfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGish(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'VGGish'\n",
    "        self.trainable = False\n",
    "        \n",
    "        # Block 1\n",
    "        self.conv2d_1 = Conv2D(64, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_1 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "        \n",
    "        # Block 2\n",
    "        self.conv2d_2 = Conv2D(128, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_2 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "        # Block 3\n",
    "        self.conv2d_3_1 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.conv2d_3_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_3 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "        # Block 4\n",
    "        self.conv2d_4_1 = Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.conv2d_4_2 = Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_4 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "        \n",
    "        self.load_weights('../weights/vggish')\n",
    "        \n",
    "    def call(self, inputs, return_corr = True):\n",
    "        feats = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None,\n",
    "            'block4': None\n",
    "        }\n",
    "        \n",
    "        x = self.conv2d_1(inputs)\n",
    "        x = self.pool_1(x)\n",
    "        feats['block1'] = x if not return_corr else self.get_feat_corr(x)\n",
    "        \n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.pool_2(x)\n",
    "        feats['block2'] = x if not return_corr else self.get_feat_corr(x)\n",
    "        \n",
    "        x = self.conv2d_3_1(x)\n",
    "        x = self.conv2d_3_2(x)\n",
    "        x = self.pool_3(x)\n",
    "        feats['block3'] = x if not return_corr else self.get_feat_corr(x)\n",
    "        \n",
    "        x = self.conv2d_4_1(x)\n",
    "        x = self.conv2d_4_2(x)\n",
    "        x = self.pool_4(x)\n",
    "        feats['block4'] = x if not return_corr else self.get_feat_corr(x)\n",
    "                \n",
    "        return x, feats\n",
    "    \n",
    "    def get_feat_corr(self, feat):\n",
    "        feat = Reshape((-1, feat.shape[-1]))(feat)\n",
    "        feat = Permute((2, 1))(feat)\n",
    "        corr = tf.linalg.matmul(feat, feat, transpose_b=True) / (feat.shape[2] - 1)\n",
    "        corr = corr / tf.reduce_max(tf.abs(feat))\n",
    "        \n",
    "        return corr\n",
    "        \n",
    "    def model(self):\n",
    "        x = Input(shape=(960, 64, 1))\n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "    \n",
    "# # convolutional operation parameters\n",
    "# n_filters = 16\n",
    "# kernels = [3, 5, 7]\n",
    "# skips = []\n",
    "\n",
    "# history_seq = Input(shape=(WINDOW_SIZE, 1))\n",
    "# for kernel in kernels:\n",
    "#     x = Conv1D(n_filters, (kernel, ), activation = 'relu', padding = 'same')(history_seq) \n",
    "#     x = MaxPooling1D()(x)\n",
    "#     x = Conv1D(n_filters * 2, (kernel, ), activation = 'relu', padding = 'same')(x) \n",
    "#     skips.append(x)\n",
    "\n",
    "# features = Add()(skips)\n",
    "# features = BatchNormalization()(features)\n",
    "# features = Flatten()(features)\n",
    "\n",
    "# out = Dropout(0.1)(features)\n",
    "# out = Dense(256, activation = 'relu')(features)\n",
    "# out = Dropout(0.15)(out)\n",
    "# out = Dense(256, activation = 'relu')(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "650e20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMuse(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'IMuse'\n",
    "        \n",
    "        self.encoder = VGGish()\n",
    "        \n",
    "        self.bloc1_decoder = Sequential([\n",
    "            Input((64, 64)),\n",
    "            Conv1D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "            Conv1D(128, 5, activation=\"relu\", padding=\"same\"),\n",
    "            \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "defdd60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 131072)            67239936  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,239,936\n",
      "Trainable params: 67,239,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "covar = Lambda(lambda x: K.dot(K.transpose(x),x))(previousLayerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8de6b708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128, 128), dtype=float32, numpy=\n",
       "array([[[64., 64., 64., ..., 64., 64., 64.],\n",
       "        [64., 64., 64., ..., 64., 64., 64.],\n",
       "        [64., 64., 64., ..., 64., 64., 64.],\n",
       "        ...,\n",
       "        [64., 64., 64., ..., 64., 64., 64.],\n",
       "        [64., 64., 64., ..., 64., 64., 64.],\n",
       "        [64., 64., 64., ..., 64., 64., 64.]]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.ones((1, 128, 64))\n",
    "tf.linalg.matmul(x, x, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077ebc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
