{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "from tensorflow.train import BytesList\n",
    "from tensorflow.train import Example, Features, Feature\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "import librosa as lb\n",
    "\n",
    "import requests\n",
    "from tqdm import trange, tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from model import WaveletAE\n",
    "from utils import get_style_correlation_transform\n",
    "\n",
    "from vggish_preprocessing.preprocess_sound import preprocess_sound\n",
    "import vggish_preprocessing.vggish_params as vggish_params\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eaf298",
   "metadata": {},
   "source": [
    "# IMuse - Image To Music Style Transfer\n",
    "## Data EDA and Preprocessing\n",
    "\n",
    "### Image Wiki Art Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ce204",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiart_images = pd.read_csv('../data/image/WikiArt-Emotions/WikiArt-info.tsv', sep='\\t')\n",
    "print(f'{wikiart_images.shape[0]} unique images')\n",
    "wikiart_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ef8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiart_images = wikiart_images[['ID', 'Image URL']]\n",
    "wikiart_images.columns = ['id', 'url']\n",
    "wikiart_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf447dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiart_images[(wikiart_images.url.str.endswith('.jpg')) | (wikiart_images.url.str.endswith('.JPG'))].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984f513",
   "metadata": {},
   "source": [
    "Almost all of the data is .jpg so we can remove the 4 png files in order to keep the consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54026e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiart_images = wikiart_images[(wikiart_images.url.str.endswith('.jpg')) | (wikiart_images.url.str.endswith('.JPG'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_img(url, directory, file_id):\n",
    "    image = requests.get(url).content\n",
    "    with open(f'{directory}/{file_id}.jpg', 'wb') as handler:\n",
    "        handler.write(image)\n",
    "\n",
    "# for img_id, imd_url in tqdm(wikiart_images.values):\n",
    "#     download_img(imd_url, '../data/image/wikiart', img_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ddcbf3",
   "metadata": {},
   "source": [
    "### Emotion Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arts_emotions = pd.read_csv('../data/image/WikiArt-Emotions/WikiArt-Emotions-All.tsv', sep='\\t')\n",
    "arts_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2596da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the \"Image Only\" emotions\n",
    "arts_emotions = arts_emotions[['ID', *arts_emotions.columns[29:49]]]\n",
    "arts_emotions.columns = [col.split(':')[-1].strip() for col in arts_emotions.columns]\n",
    "arts_emotions.columns = ['id', *arts_emotions.columns[1:]]\n",
    "arts_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column with top emotion associated with artwork \n",
    "prob_df4 = arts_emotions.loc[:, ('agreeableness', 'anger', 'anticipation','arrogance', 'disagreeableness',\n",
    "       'disgust', 'fear','gratitude', 'happiness', 'humility', 'love',\n",
    "       'optimism', 'pessimism','regret', 'sadness','shame', 'shyness',\n",
    "       'surprise', 'trust','neutral')]\n",
    "arts_emotions[\"emotion\"] = prob_df4.idxmax(axis = 1)\n",
    "arts_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arts_emotions.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0514c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_quadrants = {\n",
    "    'happiness': 'Q1',\n",
    "    'surprise': 'Q1',\n",
    "    'sadness': 'Q3',\n",
    "    'disagreeableness': 'Q2',\n",
    "    'fear': 'Q2',\n",
    "    'trust': 'Q1',\n",
    "    'anticipation': 'Q2',\n",
    "    'humility': 'Q4',\n",
    "    'shame': 'Q3',\n",
    "    'arrogance': 'Q2',\n",
    "    'love': 'Q1',\n",
    "    'disgust': 'Q2',\n",
    "    'optimism': 'Q1',\n",
    "    'anger': 'Q2',\n",
    "    'pessimism': 'Q3',\n",
    "    'neutral': 'Q4',\n",
    "    'gratitude': 'Q1',\n",
    "    'agreeableness': 'Q4',\n",
    "    'shyness': 'Q4',\n",
    "    'happy': 'Q1',\n",
    "    'sad': 'Q3',\n",
    "    'tender': 'Q1',\n",
    "    'high val.': 'Q1',\n",
    "    'low val.': 'Q2',\n",
    "    'high ener.': 'Q1',\n",
    "    'low ener.': 'Q4',\n",
    "    'high tens.': 'Q2',\n",
    "    'low tens.': 'Q4',\n",
    "    'anger high': 'Q2',\n",
    "    'anger mod.': 'Q3',\n",
    "    'fear high': 'Q2',\n",
    "    'fear mod.': 'Q3',\n",
    "    'happy high': 'Q1',\n",
    "    'happy mod.': 'Q2',\n",
    "    'sad high': 'Q3',\n",
    "    'sad mod.': 'Q4',\n",
    "    'tender high': 'Q4',\n",
    "    'tender mod.': 'Q1',\n",
    "    'valence pos. high': 'Q1',\n",
    "    'valence pos. mod.': 'Q1',\n",
    "    'valence neg. mod.': 'Q2',\n",
    "    'valence neg. high': 'Q2',\n",
    "    'energy pos. high': 'Q1',\n",
    "    'energy pos. mod.': 'Q1',\n",
    "    'energy neg. mod.': 'Q2',\n",
    "    'energy neg. high': 'Q2',\n",
    "    'tension pos. high': 'Q2',\n",
    "    'tension pos. mod.': 'Q1',\n",
    "    'tension neg. mod.': 'Q3',\n",
    "    'tension neg. high': 'Q4',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5008b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_quadrant(df):\n",
    "    df['quadrant'] = 0\n",
    "\n",
    "    def get_quadrant(row):\n",
    "        row.quadrant = emotion_quadrants[row.emotion]\n",
    "        \n",
    "        return row\n",
    "\n",
    "    return df.apply(get_quadrant, axis=1)\n",
    "\n",
    "arts_emotions = set_quadrant(arts_emotions)\n",
    "arts_emotions = arts_emotions[['id', 'quadrant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f9902",
   "metadata": {},
   "source": [
    "### Music Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2669737",
   "metadata": {},
   "outputs": [],
   "source": [
    "osts_set_1 = pd.read_csv('../data/music/OSTs/set1_tracklist.csv', index_col=0)\n",
    "osts_set_1['set'] = 1\n",
    "osts_set_2 = pd.read_csv('../data/music/OSTs/set2_tracklist.csv', index_col=0)\n",
    "osts_set_2['set'] = 2\n",
    "\n",
    "osts = pd.concat([osts_set_1, osts_set_2])\n",
    "osts = osts[['Emotion', 'set']]\n",
    "osts.columns = ['emotion', 'set']\n",
    "osts['emotion'] = osts.emotion.str.lower()\n",
    "osts = set_quadrant(osts)\n",
    "\n",
    "osts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('../data/music/others/annotations.csv')\n",
    "songs.columns = ['song', 'quadrant']\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "osts['music'] = '../data/music/OSTs/Set' + osts.set.astype(str) + '/' + osts.index.map('{0:0=3d}'.format) + '.mp3'\n",
    "songs['music'] = '../data/music/others/' + songs.quadrant + '/' + songs.song + '.mp3'\n",
    "\n",
    "osts = osts[['music', 'quadrant']]\n",
    "songs = songs[['music', 'quadrant']]\n",
    "\n",
    "music_data = pd.concat([osts, songs]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3a4e4",
   "metadata": {},
   "source": [
    "### Map Music to Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_related_music(df, already_set_df = None, use_second_set = False):\n",
    "    df['music'] = ''\n",
    "\n",
    "    q1_ids = music_data[(music_data.quadrant == 'Q1')].music.values\n",
    "    q2_ids = music_data[(music_data.quadrant == 'Q2')].music.values\n",
    "    q3_ids = music_data[(music_data.quadrant == 'Q3')].music.values\n",
    "    q4_ids = music_data[(music_data.quadrant == 'Q4')].music.values\n",
    "    \n",
    "    df.loc[df.quadrant == 'Q1', 'music'] = np.random.choice(\n",
    "        q1_ids,\n",
    "        df[df.quadrant == 'Q1'].shape[0],\n",
    "        replace=q1_ids.shape[0] < df[df.quadrant == 'Q1'].shape[0]\n",
    "    )\n",
    "    df.loc[df.quadrant == 'Q2', 'music'] = np.random.choice(\n",
    "        q2_ids,\n",
    "        df[df.quadrant == 'Q2'].shape[0],\n",
    "        replace=q2_ids.shape[0] < df[df.quadrant == 'Q2'].shape[0]\n",
    "    )\n",
    "    df.loc[df.quadrant == 'Q3', 'music'] = np.random.choice(\n",
    "        q3_ids,\n",
    "        df[df.quadrant == 'Q3'].shape[0],\n",
    "        replace=q3_ids.shape[0] < df[df.quadrant == 'Q3'].shape[0]\n",
    "    )\n",
    "    df.loc[df.quadrant == 'Q4', 'music'] = np.random.choice(\n",
    "        q4_ids,\n",
    "        df[df.quadrant == 'Q4'].shape[0],\n",
    "        replace=q4_ids.shape[0] < df[df.quadrant == 'Q4'].shape[0]\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = set_related_music(arts_emotions)\n",
    "data['img'] = '../data/image/wikiart/' + data.id + '.jpg'\n",
    "data.drop(['id'], 1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8cee28",
   "metadata": {},
   "source": [
    "### TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d421c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.music, data.img, test_size=0.08, stratify=data.quadrant, shuffle=True)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.15)\n",
    "\n",
    "train_ds = pd.DataFrame({'x': x_train, 'y': y_train})\n",
    "test_ds = pd.DataFrame({'x': x_test, 'y': y_test})\n",
    "val_ds = pd.DataFrame({'x': x_val, 'y': y_val})\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(train_ds))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(test_ds))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(val_ds))\n",
    "\n",
    "x_train.reset_index(drop=True)\n",
    "x_test.reset_index(drop=True)\n",
    "\n",
    "x_val.reset_index(drop=True)\n",
    "y_val.reset_index(drop=True)\n",
    "\n",
    "y_train.reset_index(drop=True)\n",
    "y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c55f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value, raw_string = False):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.numpy() if not raw_string else value]))\n",
    "\n",
    "def normalized_wt_downsampling(x, wavelet, level):\n",
    "        LL = pywt.wavedec2(x, wavelet, 'periodization', level)[0]\n",
    "        LL = LL / np.abs(LL).max()\n",
    "\n",
    "        return LL\n",
    "\n",
    "def per_channel_wd(img, level=1, wavelet='haar'):\n",
    "    r, g, b = tf.unstack(img, axis=2)\n",
    "    r = normalized_wt_downsampling(r, wavelet, level)\n",
    "    g = normalized_wt_downsampling(g, wavelet, level)\n",
    "    b = normalized_wt_downsampling(b, wavelet, level)\n",
    "\n",
    "    return tf.stack([r, g, b], axis=2)\n",
    "\n",
    "class DatasetGenerator:\n",
    "    def __init__(self, max_dim_size = 128, vgg_input_max_size = 512):\n",
    "        self.max_dim_size = max_dim_size\n",
    "        self.vgg_input_max_size = vgg_input_max_size\n",
    "        self.wavelet_ae = WaveletAE()\n",
    "    \n",
    "    def load_image(self, img_path):\n",
    "        self.img_path = img_path\n",
    "        self.img_bytes = tf.io.read_file(img_path)\n",
    "        self.img_raw = tf.image.decode_image(self.img_bytes, channels = 3, dtype=tf.float32)\n",
    "        \n",
    "#         dwt_level = tf.experimental.numpy.log2(tf.reduce_max(self.img_raw.shape) / (self.max_dim_size + ((tf.reduce_max(self.img_raw.shape) - tf.reduce_min(self.img_raw.shape)) / 2)))\n",
    "#         dwt_level = tf.round(dwt_level)\n",
    "#         dwt_level = tf.cast(dwt_level, tf.uint8)\n",
    "        \n",
    "#         self.img_resized = per_channel_wd(self.img_raw, dwt_level)\n",
    "#         self.img_resized = tfa.image.gaussian_filter2d(self.img_resized, (6, 6), sigma=6e-1)\n",
    "#         self.img_resized = tf.image.resize_with_crop_or_pad(self.img_resized, self.max_dim_size, self.max_dim_size)\n",
    "        \n",
    "        ar = self.img_raw.shape[0] / self.img_raw.shape[1]\n",
    "        if ar > 1:\n",
    "            size = [self.vgg_input_max_size, int(self.vgg_input_max_size / ar)]\n",
    "        else:\n",
    "            size = [int(ar * self.vgg_input_max_size), self.vgg_input_max_size]\n",
    "\n",
    "        self.img_raw = tf.image.resize(self.img_raw, size)\n",
    "            \n",
    "    def load_music(self, music_path):\n",
    "        audio_data, sr = lb.load(music_path)\n",
    "        train_len = 10 * sr\n",
    "        random_start = np.random.randint(audio_data.shape[0] - train_len)\n",
    "        audio_data = audio_data[random_start : random_start + train_len]\n",
    "\n",
    "        self.spec = preprocess_sound(audio_data, sr)\n",
    "        \n",
    "    def get_style_transormations(self):\n",
    "        feat, _ = self.wavelet_ae.get_features(tf.expand_dims(self.img_raw, 0))\n",
    "        self.style_ede, self.style_means = self.wavelet_ae.get_style_correlations(tf.expand_dims(self.img_raw, 0), ede=False)\n",
    "\n",
    "        for i in range(len(self.style_ede)):\n",
    "            self.style_ede[i] = tf.cast(tfp.math.fill_triangular_inverse(self.style_ede[i], upper=True), tf.float16)\n",
    "\n",
    "        for i in range(len(self.style_means)):\n",
    "            self.style_means[i] = tf.cast(self.style_means[i], tf.float16)\n",
    "    \n",
    "    def process(self, music, img):\n",
    "        self.load_image(img)\n",
    "        self.load_music(music)\n",
    "        self.get_style_transormations()\n",
    "    \n",
    "    def serialize_information(self):\n",
    "#         img_resized = tf.cast(self.img_resized * 255, tf.uint8)\n",
    "#         img_resized = tf.image.encode_jpeg(img_resized)\n",
    "        \n",
    "        features = Features(feature = {\n",
    "            'img_path': _bytes_feature(self.img_path.encode('utf-8'), raw_string=True),\n",
    "            \n",
    "#             'resized_image': _bytes_feature(img_resized),\n",
    "            \n",
    "            'block1_feat': _bytes_feature(tf.io.serialize_tensor(self.style_ede[0][0])),\n",
    "            'block1_mean': _bytes_feature(tf.io.serialize_tensor(self.style_means[0][0])),\n",
    "            \n",
    "            'block2_feat': _bytes_feature(tf.io.serialize_tensor(self.style_ede[1][0])),\n",
    "            'block2_mean': _bytes_feature(tf.io.serialize_tensor(self.style_means[1][0])),\n",
    "            \n",
    "            'block3_feat': _bytes_feature(tf.io.serialize_tensor(self.style_ede[2][0])),\n",
    "            'block3_mean': _bytes_feature(tf.io.serialize_tensor(self.style_means[2][0])),\n",
    "            \n",
    "            'block4_feat': _bytes_feature(tf.io.serialize_tensor(self.style_ede[3][0])),\n",
    "            'block4_mean': _bytes_feature(tf.io.serialize_tensor(self.style_means[3][0])),\n",
    "\n",
    "            'music_spec': _bytes_feature(tf.io.serialize_tensor(self.spec)),\n",
    "        })\n",
    "\n",
    "        return Example(features=features).SerializeToString()\n",
    "\n",
    "datagen = DatasetGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0cdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = DatasetGenerator()\n",
    "tf_record_options = tf.io.TFRecordOptions(compression_type = \"GZIP\")\n",
    "\n",
    "BASE_DATA_DIR = Path(os.getcwd()).parent  / \"data\" / \"tfrecords-whithout-ede\"\n",
    "\n",
    "def write_as_TFRecords(dataset, target_dir, batch_size, datagen):\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset_len = len(list(dataset))\n",
    "    for part_id, data in enumerate(dataset):\n",
    "        filename = str(target_dir / f\"{part_id}.tfrecord\")\n",
    "        with tf.io.TFRecordWriter(filename, options = tf_record_options) as writer:\n",
    "            for music, image in tqdm(data):\n",
    "                music_path = music.numpy().decode(\"utf-8\")\n",
    "                image_path = image.numpy().decode(\"utf-8\")\n",
    "                if not Path(music_path).is_file() or not Path(image_path).is_file():\n",
    "                    continue\n",
    "                datagen.process(music_path, image_path)\n",
    "                writer.write(datagen.serialize_information())\n",
    "            writer.close()\n",
    "            \n",
    "write_as_TFRecords(dataset = train_ds,\n",
    "                   target_dir = BASE_DATA_DIR / \"train\", \n",
    "                   batch_size = 1024,\n",
    "                   datagen = datagen)\n",
    "\n",
    "write_as_TFRecords(dataset = test_ds,\n",
    "                   target_dir = BASE_DATA_DIR / \"test\", \n",
    "                   batch_size = len(list(test_ds)),\n",
    "                   datagen = datagen)\n",
    "\n",
    "write_as_TFRecords(dataset = val_ds,\n",
    "                   target_dir = BASE_DATA_DIR / \"val\", \n",
    "                   batch_size = len(list(val_ds)),\n",
    "                   datagen = datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2752e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
