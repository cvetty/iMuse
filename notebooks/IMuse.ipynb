{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1688d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, BatchNormalization, Flatten, Reshape, Permute, Add, ReLU, Input, MaxPool1D, Conv1D, Conv2D, Dense, MaxPooling2D, GlobalMaxPooling2D, UpSampling2D, Concatenate\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44cde09",
   "metadata": {},
   "source": [
    "### VGGish model TF2 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76bdfa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block1': <tf.Tensor: shape=(1, 2080), dtype=float32, numpy=\n",
       " array([[3.5273850e-05, 7.6265947e-05, 2.8493220e-04, ..., 3.1446838e-03,\n",
       "         5.9016519e-03, 1.5245323e-03]], dtype=float32)>,\n",
       " 'block2': <tf.Tensor: shape=(1, 8256), dtype=float32, numpy=\n",
       " array([[0.06765261, 0.00130095, 0.08475295, ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32)>,\n",
       " 'block3': <tf.Tensor: shape=(1, 32896), dtype=float32, numpy=\n",
       " array([[1.6588690e-03, 1.6743097e-05, 3.4623828e-03, ..., 2.1995839e-03,\n",
       "         1.5790742e-03, 4.5692816e-04]], dtype=float32)>,\n",
       " 'block4': <tf.Tensor: shape=(1, 131328), dtype=float32, numpy=\n",
       " array([[0.        , 0.        , 0.        , ..., 0.01070831, 0.00795639,\n",
       "         0.01157182]], dtype=float32)>}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VGGish(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'VGGish'\n",
    "        self.trainable = False\n",
    "        \n",
    "        # Block 1\n",
    "        self.conv2d_1 = Conv2D(64, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_1 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "        \n",
    "        # Block 2\n",
    "        self.conv2d_2 = Conv2D(128, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_2 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "        # Block 3\n",
    "        self.conv2d_3_1 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.conv2d_3_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_3 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "        # Block 4\n",
    "        self.conv2d_4_1 = Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.conv2d_4_2 = Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same')\n",
    "        self.pool_4 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')\n",
    "        \n",
    "#         self.load_weights('../weights/vggish')\n",
    "        \n",
    "    def call(self, inputs, return_corr = True, encode_level = None):\n",
    "        feats = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None,\n",
    "            'block4': None\n",
    "        }\n",
    "        \n",
    "        x = self.conv2d_1(inputs)\n",
    "        x = self.pool_1(x)\n",
    "        feats['block1'] = x if not return_corr else self.get_feat_corr(x)\n",
    "        \n",
    "        if encode_level == 1:\n",
    "            return x, feats['block1']\n",
    "        \n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.pool_2(x)\n",
    "        feats['block2'] = x if not return_corr else self.get_feat_corr(x)\n",
    "        \n",
    "        if encode_level == 2:\n",
    "            return x, feats['block2']\n",
    "        \n",
    "        x = self.conv2d_3_1(x)\n",
    "        x = self.conv2d_3_2(x)\n",
    "        x = self.pool_3(x)\n",
    "        feats['block3'] = x if not return_corr else self.get_feat_corr(x)\n",
    "        \n",
    "        if encode_level == 3:\n",
    "            return x, feats['block3']\n",
    "        \n",
    "        x = self.conv2d_4_1(x)\n",
    "        x = self.conv2d_4_2(x)\n",
    "        x = self.pool_4(x)\n",
    "        feats['block4'] = x if not return_corr else self.get_feat_corr(x)\n",
    "                \n",
    "        return x, feats\n",
    "    \n",
    "    def get_feat_corr(self, feat):\n",
    "        feat = Reshape((-1, feat.shape[-1]))(feat)\n",
    "        feat = Permute((2, 1))(feat)\n",
    "        corr = tf.linalg.matmul(feat, feat, transpose_b=True) / (feat.shape[2] - 1)\n",
    "        corr = tfp.math.fill_triangular_inverse(corr, upper=True)\n",
    "        corr = corr / tf.reduce_max(tf.abs(feat))\n",
    "        \n",
    "        return corr\n",
    "        \n",
    "    def model(self):\n",
    "        x = Input(shape=(960, 64, 1))\n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "    \n",
    "    \n",
    "# # convolutional operation parameters\n",
    "# n_filters = 16\n",
    "# kernels = [1, 3, 7]\n",
    "# skips = []\n",
    "\n",
    "# history_seq = Input(shape=(WINDOW_SIZE, 1))\n",
    "# for kernel in kernels:\n",
    "#     x = Conv1D(n_filters, (kernel, ), activation = 'relu', padding = 'same')(history_seq) \n",
    "#     x = MaxPooling1D()(x)\n",
    "#     x = Conv1D(n_filters * 2, (kernel, ), activation = 'relu', padding = 'same')(x) \n",
    "#     skips.append(x)\n",
    "\n",
    "# features = Add()(skips)\n",
    "# features = BatchNormalization()(features)\n",
    "# features = Flatten()(features)\n",
    "\n",
    "# out = Dropout(0.1)(features)\n",
    "# out = Dense(256, activation = 'relu')(features)\n",
    "# out = Dropout(0.15)(out)\n",
    "# out = Dense(256, activation = 'relu')(out)\n",
    "\n",
    "vgg = VGGish()\n",
    "_, feat = vgg(tf.random.uniform((1, 128, 128, 1)))\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3cc6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "# x = pca.fit_transform(feat['block4'].numpy()[0])\n",
    "# pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5267bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2080), dtype=float32, numpy=\n",
       "array([[3.5273850e-05, 7.6265947e-05, 2.8493220e-04, ..., 3.1446838e-03,\n",
       "        5.9016519e-03, 1.5245323e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat['block1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee1368b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650e20ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling layer \"IMuse\" (type IMuse).\n\nUnimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 128, 60, 1), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbloc1_decoder \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m      9\u001b[0m             Input((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)),\n\u001b[1;32m     10\u001b[0m             Conv1D(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m             Conv1D(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m             \n\u001b[1;32m     13\u001b[0m         ])\n\u001b[1;32m     15\u001b[0m imuse \u001b[38;5;241m=\u001b[39m IMuse()\n\u001b[0;32m---> 16\u001b[0m \u001b[43mimuse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/iMuse/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/projects/iMuse/venv/lib/python3.8/site-packages/keras/engine/training.py:475\u001b[0m, in \u001b[0;36mModel.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_in_current_and_subclasses\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    452\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls the model on new inputs and returns the outputs as tensors.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m  In this case `call()` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnimplemented `tf.keras.Model.call()`: if you \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    476\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintend to create a `Model` with the Functional \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    477\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI, please provide `inputs` and `outputs` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    478\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments. Otherwise, subclass `Model` with an \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    479\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverridden `call()` method.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling layer \"IMuse\" (type IMuse).\n\nUnimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 128, 60, 1), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "class ExtractorCNNBlock(Model):\n",
    "    def __init__(self, filters, kernel):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv1D(filters, (kernel,), activation='relu', padding='same')\n",
    "        self.pool = MaxPooling1D()\n",
    "        self.conv2 = Conv1D(filters * 2, (kernel,), activation='relu', padding='same')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class FeatExtractor(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = ExtractorCNNBlock(16, 1)\n",
    "        self.block2 = ExtractorCNNBlock(16, 3)\n",
    "        self.block3 = ExtractorCNNBlock(16, 5)\n",
    "        self.block4 = ExtractorCNNBlock(16, 7)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.flatten = Flatten()\n",
    "        self.attention = Attention()\n",
    "        \n",
    "    def call(self, inputs, flatten = False):\n",
    "        block1_enc = self.block1(inputs)\n",
    "        block2_enc = self.block2(inputs)\n",
    "        block3_enc = self.block3(inputs)\n",
    "        block4_enc = self.block4(inputs)\n",
    "        \n",
    "        x = Add()([block1_enc, block2_enc, block3_enc, block4_enc])\n",
    "        x = self.bn(x)\n",
    "        \n",
    "        att = self.attention([x, x])\n",
    "        x = Concatenate()([x, att])\n",
    "        \n",
    "        if flatten:\n",
    "            x = self.flatten(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "class Sampler_Z(tfk.layers.Layer):\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        mu, rho = inputs\n",
    "        sd = tf.math.log(1+tf.math.exp(rho))\n",
    "        batch_size = tf.shape(mu)[0]\n",
    "        dim_z = tf.shape(mu)[1]\n",
    "        z_sample = mu + sd * tf.random.normal(shape=(batch_size, dim_z))\n",
    "        \n",
    "        return z_sample, sd\n",
    "        \n",
    "class FeaturesEncoder(Model):\n",
    "    def __init__(self, dim_z, feature_extractor=None, name=\"encoder\", **kwargs):\n",
    "        super(Encoder_Z, self).__init__(name=name, **kwargs)\n",
    "        self.dim_x = (28, 28, 1)\n",
    "        self.dim_z = dim_z\n",
    "        \n",
    "        self.feature_extractor = feature_extractor or FeatExtractor()\n",
    "        self.conv_layer_1 = tfkl.Conv1D(filters=32, kernel_size=3, strides=(2,2), padding='same', activation='relu')\n",
    "        self.conv_layer_2 = tfkl.Conv1D(filters=64, kernel_size=3, strides=(2,2), padding='same', activation='relu')\n",
    "        self.conv_layer_3 = tfkl.Conv1D(filters=128, kernel_size=3, strides=(2,2), padding='same', activation='relu')\n",
    "        \n",
    "        self.flatten_layer = tfkl.Flatten()\n",
    "        self.dense_mean = tfkl.Dense(self.dim_z, activation=None, name='z_mean')\n",
    "        self.dense_raw_stddev = tfkl.Dense(self.dim_z, activation=None, name='z_raw_stddev')\n",
    "        self.sampler_z = Sampler_Z()\n",
    "    \n",
    "    # Functional\n",
    "    def call(self, inputs, embedding=True):\n",
    "        if embedding:\n",
    "            z = self.feature_extractor(inputs)\n",
    "        else:\n",
    "            z = inputs\n",
    "            \n",
    "        z = self.conv_layer_1(z)\n",
    "        z = self.conv_layer_2(z)\n",
    "        z = self.flatten_layer(z)\n",
    "        mu = self.dense_mean(z)\n",
    "        rho = self.dense_raw_stddev(z)\n",
    "        z_sample, sd = self.sampler_z((mu,rho))\n",
    "        \n",
    "        return z_sample, mu, sd\n",
    "    \n",
    "class FeaturesDecoder(tfk.layers.Layer):\n",
    "    def __init__(self, dim_z, name=\"decoder\", **kwargs):\n",
    "        super(Decoder_X, self).__init__(name=name, **kwargs)\n",
    "        self.dim_z = dim_z\n",
    "        self.dense_z_input = tfkl.Dense(7*7*32, activation=None)\n",
    "        self.reshape_layer = tfkl.Reshape((7,7,32))\n",
    "        self.conv_transpose_layer_1 = tfkl.Conv1DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.conv_transpose_layer_2 = tfkl.Conv1DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.conv_transpose_layer_3 = tfkl.Conv1DTranspose(filters=1, kernel_size=3, strides=1, padding='same')\n",
    "    \n",
    "    # Functional\n",
    "    def call(self, z):\n",
    "        x_output = self.dense_z_input(z)\n",
    "        x_output = self.reshape_layer(x_output)\n",
    "        x_output = self.conv_transpose_layer_1(x_output)\n",
    "        x_output = self.conv_transpose_layer_2(x_output)\n",
    "        x_output = self.conv_transpose_layer_3(x_output)\n",
    "        return x_output\n",
    "        \n",
    "class FeaturesMapper(Model):\n",
    "    def __init__(self, dim_z, learning_rate, kl_weight=1, name=\"autoencoder\", **kwargs):\n",
    "        super(FeaturesMapper, self).__init__(name=name, **kwargs)\n",
    "        self.dim_x = (28, 28, 1)\n",
    "        self.dim_z = dim_z\n",
    "        self.learning_rate = learning_rate\n",
    "        self.encoder = Encoder_Z(dim_z=self.dim_z)\n",
    "        self.decoder = Decoder_X(dim_z=self.dim_z)\n",
    "        self.kl_weight = kl_weight\n",
    "        \n",
    "    # def encode_and_decode(self, x_input):\n",
    "    def call(self, x_input):\n",
    "        z_sample, mu, sd = self.encoder(x_input)\n",
    "        x_recons_logits = self.decoder(z_sample)\n",
    "        \n",
    "        kl_divergence = - 0.5 * tf.math.reduce_sum(1+tf.math.log(\n",
    "          tf.math.square(sd))-tf.math.square(mu)-tf.math.square(sd), axis=1)\n",
    "        kl_divergence = tf.math.reduce_mean(kl_divergence)\n",
    "        # self.add_loss(lambda: self.kl_weight * kl_divergence)\n",
    "        self.add_loss(self.kl_weight * kl_divergence)\n",
    "        \n",
    "        return x_recons_logits\n",
    "\n",
    "class IMuse(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'IMuse'\n",
    "        \n",
    "        self.encoder = VGGish()\n",
    "        \n",
    "        self.bloc1_decoder = Sequential([\n",
    "            Input((64, 64)),\n",
    "            Conv1D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "            Conv1D(128, 5, activation=\"relu\", padding=\"same\"),\n",
    "            \n",
    "        ])\n",
    "        \n",
    "imuse = IMuse()\n",
    "imuse(tf.zeros((1, 128, 60, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "defdd60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 131072)            67239936  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,239,936\n",
      "Trainable params: 67,239,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
