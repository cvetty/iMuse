{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, ReLU, Conv2D\n",
    "\n",
    "from tensorflow.nn import conv2d, conv2d_transpose\n",
    "from tensorflow.io import read_file\n",
    "from tensorflow.image import decode_image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv2d(x, kernel):\n",
    "    return conv2d(x, kernel, strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def _conv2d_transpose(x, kernel, output_shape):\n",
    "    return conv2d_transpose(\n",
    "            x, kernel,\n",
    "            output_shape=output_shape,\n",
    "            strides=[1, 2, 2, 1],\n",
    "            padding='SAME')\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = read_file(image_path)\n",
    "    image = decode_image(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletPooling(Layer):\n",
    "    \"\"\"\n",
    "    Wavelet Pooing Custom Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, name=''):\n",
    "        super(WaveletPooling, self).__init__()\n",
    "        self._name = name\n",
    "        square_of_2 = tf.math.sqrt(tf.constant(2, dtype=tf.float32))\n",
    "        L = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "        H = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[-1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "\n",
    "        self.LL = tf.reshape(tf.math.multiply(tf.transpose(L), L), (1, 2, 2, 1))\n",
    "        self.LH = tf.reshape(tf.math.multiply(tf.transpose(L), H), (1, 2, 2, 1))\n",
    "        self.HL = tf.reshape(tf.math.multiply(tf.transpose(H), L), (1, 2, 2, 1))\n",
    "        self.HH = tf.reshape(tf.math.multiply(tf.transpose(H), H), (1, 2, 2, 1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        LL, LH, HL, HH = self.repeat_filters(inputs.shape[-1])\n",
    "        return [_conv2d(inputs, LL),\n",
    "                _conv2d(inputs, LH),\n",
    "                _conv2d(inputs, HL),\n",
    "                _conv2d(inputs, HH)]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = (\n",
    "            input_shape[0], input_shape[1] // 2,\n",
    "            input_shape[2] // 2, input_shape[3]\n",
    "        )\n",
    "\n",
    "        return [shape, shape, shape, shape]\n",
    "\n",
    "    def repeat_filters(self, repeats):\n",
    "        # Can we optimize this?\n",
    "        return [\n",
    "            tf.transpose(tf.repeat(self.LL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.LH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HH, repeats, axis=0), (1, 2, 3, 0))\n",
    "        ]\n",
    "\n",
    "class WaveletUnpooling(Layer):\n",
    "    \"\"\"\n",
    "    Wavelet Unpooing Custom Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        super(WaveletUnpooling, self).__init__()\n",
    "        self._name = name\n",
    "        square_of_2 = tf.math.sqrt(tf.constant(2, dtype=tf.float32))\n",
    "        L = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "        H = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[-1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "\n",
    "        self.LL = tf.reshape(tf.math.multiply(tf.transpose(L), L), (1, 2, 2, 1))\n",
    "        self.LH = tf.reshape(tf.math.multiply(tf.transpose(L), H), (1, 2, 2, 1))\n",
    "        self.HL = tf.reshape(tf.math.multiply(tf.transpose(H), L), (1, 2, 2, 1))\n",
    "        self.HH = tf.reshape(tf.math.multiply(tf.transpose(H), H), (1, 2, 2, 1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        LL_in, LH_in, HL_in, HH_in, tensor_in = inputs\n",
    "        LL, LH, HL, HH = self.repeat_filters(LL_in.shape[-1])\n",
    "        out_shape = tf.shape(tensor_in)\n",
    "\n",
    "        return _conv2d_transpose(LL_in, LL, output_shape=out_shape) + _conv2d_transpose(LH_in, LH, output_shape=out_shape) + _conv2d_transpose(HL_in, HL, output_shape=out_shape) + _conv2d_transpose(HH_in, HH, output_shape=out_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        _ip_shape = input_shape[0]\n",
    "        shape = (\n",
    "            _ip_shape[0],\n",
    "            _ip_shape[1] * 2,\n",
    "            _ip_shape[2] * 2,\n",
    "            sum(ips[3] for ips in input_shape)\n",
    "        )\n",
    "\n",
    "        return shape\n",
    "\n",
    "    def repeat_filters(self, repeats):\n",
    "        # Can we optimize this?\n",
    "        return [\n",
    "            tf.transpose(tf.repeat(self.LL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.LH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "        ]\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [tf.keras.layers.InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        if s[1] == None:\n",
    "            return (None, None, None, s[3])\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad, h_pad = self.padding\n",
    "        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ReflectionPadding2D, self).get_config()\n",
    "        print(config)\n",
    "        return config\n",
    "\n",
    "class CNNBlock(Layer):\n",
    "    def __init__(self, filters, kernel, name):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self._name = name\n",
    "        \n",
    "        self.padding = ReflectionPadding2D()\n",
    "        self.conv2d = Conv2D(filters, kernel, padding = 'valid')\n",
    "        self.activation = ReLU()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.padding(inputs)\n",
    "        x = self.conv2d(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wavelet_ae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\SCHOOL\\IMuse\\notebooks\\WCT - Transfer.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/SCHOOL/IMuse/notebooks/WCT%20-%20Transfer.ipynb#ch0000004?line=63'>64</a>\u001b[0m     final_out \u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m final_out \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m alpha) \u001b[39m*\u001b[39m content_feat_raw\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/SCHOOL/IMuse/notebooks/WCT%20-%20Transfer.ipynb#ch0000004?line=64'>65</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m final_out\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/SCHOOL/IMuse/notebooks/WCT%20-%20Transfer.ipynb#ch0000004?line=66'>67</a>\u001b[0m r \u001b[39m=\u001b[39m wavelet_ae\u001b[39m.\u001b[39mtransfer(tf\u001b[39m.\u001b[39mexpand_dims(test_img, \u001b[39m0\u001b[39m), tf\u001b[39m.\u001b[39mexpand_dims(test_img_style, \u001b[39m0\u001b[39m), skips_transfer\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, decoder_transfer\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/SCHOOL/IMuse/notebooks/WCT%20-%20Transfer.ipynb#ch0000004?line=67'>68</a>\u001b[0m r \u001b[39m=\u001b[39m (r \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/SCHOOL/IMuse/notebooks/WCT%20-%20Transfer.ipynb#ch0000004?line=68'>69</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(r)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wavelet_ae' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "\n",
    "def preprocess_feat(feat, center=False):\n",
    "    feat = tf.reshape(feat, (-1, feat.shape[-1]))\n",
    "    feat = tf.transpose(feat)\n",
    "\n",
    "    feat_mean_raw = tf.math.reduce_mean(feat, 1)\n",
    "\n",
    "    if center:\n",
    "        feat_mean = tf.expand_dims(feat_mean_raw, 1)\n",
    "        feat = tf.subtract(feat, feat_mean)\n",
    "\n",
    "    return feat, feat_mean_raw\n",
    "\n",
    "def center_feat(feat):\n",
    "    feat_mean = tf.math.reduce_mean(feat, 1)\n",
    "    feat_mean = tf.expand_dims(feat_mean, 1)\n",
    "    return tf.subtract(feat, feat_mean)\n",
    "\n",
    "def get_svd(feat, test = False):\n",
    "    feat = center_feat(feat)\n",
    "    feat = tf.matmul(feat, feat, transpose_b=True) / (feat.shape[1] - 1)\n",
    "    feat = feat + tf.eye(feat.shape[0])\n",
    "    if test:\n",
    "        feat -= tf.reduce_mean(feat, 0)\n",
    "        feat /= tf.math.reduce_std(feat)\n",
    "\n",
    "        feat *= 15\n",
    "    \n",
    "    return tf.linalg.svd(feat)\n",
    "\n",
    "def get_style_correlation_transform(feat, return_mean=False, normalize=False):\n",
    "    feat, mean = preprocess_feat(feat)\n",
    "    s_e, _, s_v = get_svd(feat, test=True)\n",
    "    # The inverse of the content singular values matrix operation (^-0.5)\n",
    "    s_e = tf.pow(s_e, 0.5)\n",
    "\n",
    "    EDE = tf.matmul(tf.matmul(s_v, tf.linalg.diag(s_e)), s_v, transpose_b=True)\n",
    "\n",
    "    if normalize:\n",
    "        EDE = EDE / tf.reduce_max(tf.abs(EDE))\n",
    "\n",
    "    return (EDE, mean) if return_mean else EDE\n",
    "\n",
    "def wct(content_feat_raw, style_feat_raw, alpha = 1):\n",
    "    style_EDE, style_mean = get_style_correlation_transform(style_feat_raw, return_mean = True)\n",
    "    content_feat, content_mean = preprocess_feat(content_feat_raw, center=True)\n",
    "    \n",
    "    c_e, _, c_v = get_svd(content_feat)\n",
    "    c_e = tf.pow(c_e, -0.5)\n",
    "    \n",
    "    content_EDE = tf.matmul(tf.matmul(c_v, tf.linalg.diag(c_e)), c_v, transpose_b=True)\n",
    "    content_whitened = tf.matmul(content_EDE, content_feat)\n",
    "\n",
    "    final_out = tf.matmul(style_EDE, content_whitened)\n",
    "    final_out = tf.add(final_out, tf.expand_dims(style_mean, 1))\n",
    "    final_out = tf.clip_by_value(\n",
    "        final_out,\n",
    "        tf.math.reduce_min(content_feat),\n",
    "        tf.math.reduce_max(content_feat),\n",
    "    )\n",
    "    \n",
    "    final_out = tf.reshape(tf.transpose(final_out), content_feat_raw.shape)\n",
    "    final_out = alpha * final_out + (1 - alpha) * content_feat_raw\n",
    "    return final_out\n",
    "\n",
    "r = wavelet_ae.transfer(tf.expand_dims(test_img, 0), tf.expand_dims(test_img_style, 0), skips_transfer=False, decoder_transfer=False)[0]\n",
    "r = (r * 255).numpy().astype(np.uint8)\n",
    "plt.imshow(r)\n",
    "plt.imsave('./test_std-16.png', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletEncoder'\n",
    "        \n",
    "        self.preprocessing_conv2d = Conv2D(3, 1, padding = 'valid')\n",
    "        \n",
    "        ### Block 1\n",
    "        self.block1_conv2d_1 = CNNBlock(64, 3, 'WE_block1_conv2d_1')\n",
    "        self.block1_conv2d_2 = CNNBlock(64, 3, 'WE_block1_conv2d_2')\n",
    "        self.block1_pooling = WaveletPooling('WE_block1_pooling')\n",
    "        \n",
    "        ### Block 2\n",
    "        self.block2_conv2d_1 = CNNBlock(128, 3, 'WE_block2_conv2d_1')\n",
    "        self.block2_conv2d_2 = CNNBlock(128, 3, 'WE_block2_conv2d_2')\n",
    "        self.block2_pooling = WaveletPooling('WE_block2_pooling')\n",
    "        \n",
    "        ### Block 3\n",
    "        self.block3_conv2d_1 = CNNBlock(256, 3, 'WE_block3_conv2d_1')\n",
    "        self.block3_conv2d_2 = CNNBlock(256, 3, 'WE_block3_conv2d_2')\n",
    "        self.block3_conv2d_3 = CNNBlock(256, 3, 'WE_block3_conv2d_3')\n",
    "        self.block3_conv2d_4 = CNNBlock(256, 3, 'WE_block3_conv2d_4')\n",
    "        self.block3_pooling = WaveletPooling('WE_block3_pooling')\n",
    "        \n",
    "        ### Block 4\n",
    "        self.block4_conv2d_1 = CNNBlock(512, 3, 'WE_block4_conv2d_1')\n",
    "\n",
    "    def call(self, inputs, style_feat = None, trainable = False):\n",
    "        wavelet_skips = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None,\n",
    "        }\n",
    "        \n",
    "        features = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None\n",
    "        }\n",
    "        \n",
    "        x = self.preprocessing_conv2d(inputs)\n",
    "        \n",
    "        x = self.block1_conv2d_1(x)\n",
    "        x = self.block1_conv2d_2(x)\n",
    "        LL_1, LH_1, HL_1, HH_1 = self.block1_pooling(x)\n",
    "        wavelet_skips['block1'] = [LH_1, HL_1, HH_1, x]\n",
    "        features['block1'] = LL_1\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_1 = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (LL_1, style_feat['block1']),\n",
    "                dtype=LL_1.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block2_conv2d_1(LL_1)\n",
    "        x = self.block2_conv2d_2(x)\n",
    "        LL_2, LH_2, HL_2, HH_2 = self.block2_pooling(x)\n",
    "        wavelet_skips['block2'] = [LH_2, HL_2, HH_2, x]\n",
    "        features['block2'] = LL_2\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_2 = tf.map_fn(\n",
    "                lambda y: wct(y[0], y[1]),\n",
    "                (LL_2, style_feat['block2']),\n",
    "                dtype=LL_2.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block3_conv2d_1(LL_2)\n",
    "        x = self.block3_conv2d_2(x)\n",
    "        x = self.block3_conv2d_3(x)\n",
    "        x = self.block3_conv2d_4(x)\n",
    "        LL_3, LH_3, HL_3, HH_3 = self.block3_pooling(x)\n",
    "        wavelet_skips['block3'] = [LH_3, HL_3, HH_3, x]\n",
    "        features['block3'] = LL_3\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_3 = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (LL_3, style_feat['block3']),\n",
    "                dtype=LL_3.dtype\n",
    "            )\n",
    "        \n",
    "        x = self.block4_conv2d_1(LL_3)\n",
    "        features['block4'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block4']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        return x, wavelet_skips, features\n",
    "    \n",
    "class WaveletDecoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletDecoder'\n",
    "\n",
    "        ### Block 3\n",
    "        self.block3_conv2d_1 = CNNBlock(256, 3, 'WD_block4_conv2d_1')\n",
    "        self.block3_unpooling = WaveletUnpooling('WD_block4_unpooling')\n",
    "        self.block3_conv2d_2 = CNNBlock(256, 3, 'WD_block3_conv2d_2')\n",
    "        self.block3_conv2d_3 = CNNBlock(256, 3, 'WD_block3_conv2d_3')\n",
    "        self.block3_conv2d_4 = CNNBlock(256, 3, 'WD_block3_conv2d_4')\n",
    "\n",
    "        ### Block 2\n",
    "        self.block2_conv2d_1 = CNNBlock(128, 3, 'WE_block2_conv2d_1')\n",
    "        self.block2_unpooling = WaveletUnpooling('WE_block2_unpooling')\n",
    "        self.block2_conv2d_2 = CNNBlock(128, 3, 'WE_block2_conv2d_2')\n",
    "\n",
    "        ### Block 1\n",
    "        self.block1_conv2d_1 = CNNBlock(64, 3, 'WE_block1_conv2d_1')\n",
    "        self.block1_unpooling = WaveletUnpooling('WE_block1_unpooling')\n",
    "        self.block1_conv2d_2 = CNNBlock(64, 3, 'WE_block1_conv2d_2')\n",
    "\n",
    "        self.post_processing_padding = ReflectionPadding2D()\n",
    "        self.post_processing_conv2d = Conv2D(3, 3, padding = 'valid')\n",
    "\n",
    "    def call(self, inputs, skips, style_feat = None, trainable = False):\n",
    "        features = {\n",
    "            'block3': None,\n",
    "            'block2': None,\n",
    "            'block1': None,\n",
    "        }\n",
    "        \n",
    "        x = self.block3_conv2d_1(inputs)\n",
    "        x = self.block3_unpooling([x, *skips['block3']])\n",
    "        x = self.block3_conv2d_2(x)\n",
    "        x = self.block3_conv2d_3(x)\n",
    "        x = self.block3_conv2d_4(x)\n",
    "        features['block3'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block3']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "        \n",
    "        x = self.block2_conv2d_1(x)\n",
    "        x = self.block2_unpooling([x, *skips['block2']])\n",
    "        x = self.block2_conv2d_2(x)\n",
    "        features['block2'] = x\n",
    "\n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block2']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block1_conv2d_1(x)\n",
    "        x = self.block1_unpooling([x, *skips['block1']])\n",
    "        x = self.block1_conv2d_2(x)\n",
    "        features['block1'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block1']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.post_processing_padding(x)\n",
    "        x = self.post_processing_conv2d(x)\n",
    "\n",
    "        return x, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.preprocessing_conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.preprocessing_conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.post_processing_conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.post_processing_conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block1_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block1_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block1_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block1_conv2d_2.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block2_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block2_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block2_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block2_conv2d_2.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_2.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_3.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_3.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_4.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block3_conv2d_4.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block4_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).encoder.block4_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_2.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_3.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_3.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_4.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_4.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_2.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_2.conv2d.bias\n"
     ]
    }
   ],
   "source": [
    "class WaveletAE(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletAE'\n",
    "        self.encoder = WaveletEncoder()\n",
    "        self.decoder = WaveletDecoder()\n",
    "        self.load_weights('../weights/wavelet_autoencoder')\n",
    "\n",
    "    def call(self, inputs, trainable = False):\n",
    "        x, skips, _ = self.encoder(inputs)\n",
    "        output, _ = self.decoder(x, skips)\n",
    "\n",
    "        return output\n",
    "        \n",
    "    def transfer(self, content_img, style_img, encoder_transfer = True, skips_transfer = True, decoder_transfer = True, alpha = 1):\n",
    "        style_features, style_skips = self.get_features(style_img)\n",
    "        x, content_skips, _ = self.encoder(content_img, style_features['encoder'] if encoder_transfer else None)\n",
    "        \n",
    "        if skips_transfer:\n",
    "            for key in content_skips.keys():\n",
    "                for i in range(3):\n",
    "                    content_skips[key][0] = tf.map_fn(\n",
    "                        lambda x: wct(x[0], x[1]),\n",
    "                        (content_skips[key][0], style_skips[key][0]),\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "                \n",
    "        out, _ = self.decoder(x, content_skips, style_features['decoder'] if decoder_transfer else None)\n",
    "        out = tf.clip_by_value(out, 0, 1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_features(self, inputs):\n",
    "        encoder_out, skips, encoder_feat = self.encoder(inputs)\n",
    "        _, decoder_feat = self.decoder(encoder_out, skips)\n",
    "        \n",
    "        features = {\n",
    "            'encoder': encoder_feat,\n",
    "            'decoder': decoder_feat,\n",
    "        }\n",
    "        \n",
    "        return features, skips\n",
    "    \n",
    "    def get_style_correlations(self, inputs, blocks=['block1', 'block2', 'block3', 'block4'], ede=True, normalize=True):\n",
    "        _, _, encoder_feat = self.encoder(inputs)\n",
    "        correlations = []\n",
    "        means = []\n",
    "\n",
    "        def process_correlation(feature_map, normalize=normalize):\n",
    "            feat, _ = preprocess_feat(feature_map, center=True)\n",
    "            feat = tf.matmul(feat, feat, transpose_b=True) / (feat.shape[1] - 1)\n",
    "\n",
    "            if normalize:\n",
    "                feat = feat / tf.reduce_max(tf.abs(feat))\n",
    "\n",
    "            return feat\n",
    "\n",
    "        def process_feat(feat):\n",
    "            if ede:\n",
    "                return get_style_correlation_transform(feat, normalize=normalize)\n",
    "            else:\n",
    "                return process_correlation(feat)\n",
    "\n",
    "        for block in blocks:\n",
    "            corr = tf.map_fn(process_feat, encoder_feat[block])\n",
    "            mean = tf.map_fn(lambda feat: preprocess_feat(feat, center=False)[1], encoder_feat[block])\n",
    "            correlations.append(corr)\n",
    "            means.append(mean)\n",
    "\n",
    "        return correlations, means\n",
    "        \n",
    "test_img = tf.io.read_file('../assets/moli_content.jpg')\n",
    "test_img = tf.image.decode_image(test_img, dtype=tf.float16)\n",
    "\n",
    "test_img_style = tf.io.read_file(r\"D:\\Projects\\SCHOOL\\IMuse\\data\\image\\wikiart\\57726e19edc2cb3880b5f5d5.jpg\")\n",
    "test_img_style = tf.image.decode_image(test_img_style, dtype=tf.float16)\n",
    "test_img_style = tf.image.resize(test_img_style, (test_img_style.shape[0] // 4, test_img_style.shape[1] // 4))\n",
    "\n",
    "wavelet_ae = WaveletAE()\n",
    "r = wavelet_ae.transfer(tf.expand_dims(test_img, 0), tf.expand_dims(test_img_style, 0), skips_transfer=False, decoder_transfer=False)[0]\n",
    "plt.imshow(r)\n",
    "# wavelet_ae.get_style_correlations(tf.expand_dims(test_img, 0))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([ 0.70411617, -0.12151422, -0.42485553, -1.5503218 , -1.5069814 ,\n",
       "        0.45975617, -0.55092835, -0.73550427, -2.6660464 , -1.0141574 ,\n",
       "       -1.0673672 ,  0.34919396, -0.19565134,  0.51909757,  1.6218679 ,\n",
       "       -0.07415855, -0.87449014,  0.5978281 ,  0.39578155,  0.45743504,\n",
       "        1.4497619 , -1.1626931 , -0.23420776,  0.5692032 ,  1.2464049 ,\n",
       "        0.99529517,  0.20409118,  0.49351656,  0.2175792 ,  0.31317252,\n",
       "       -1.281649  ,  0.3587559 , -1.6573917 , -0.6577175 , -0.32875746,\n",
       "       -0.05657949,  0.21723872,  0.03681321, -0.05905047,  1.4306748 ,\n",
       "        1.8873634 ,  0.91977787,  0.66978186, -0.61946094, -0.86185205,\n",
       "        0.5776125 , -0.7243503 , -0.04246671,  0.68512124,  0.638068  ,\n",
       "       -1.5401741 ,  0.11545877,  0.05387623,  1.4452695 , -1.3545693 ,\n",
       "        1.023109  ,  1.9014244 ,  0.6533844 ,  1.4911757 ,  0.22869042,\n",
       "        0.19650587,  0.581942  ,  1.0002816 ,  0.33854994], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_from_corr_matrix(sigma, num_features = None, eigenvalues = None, eigenvectors = None):\n",
    "    data = tf.eye(sigma.shape[0], num_features)\n",
    "\n",
    "    if not eigenvectors or not eigenvectors:\n",
    "        eigenvalues, u, eigenvectors = tf.linalg.svd(sigma)\n",
    "        eigenvalues = tf.linalg.diag(eigenvalues)\n",
    "        \n",
    "    data = tf.matmul(tf.matmul(eigenvectors, tf.sqrt(eigenvalues)), data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# test = tf.random.normal((8*8, 64))\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.transpose(test)\n",
    "test_corr = tf.matmul(test, test, transpose_b=True)\n",
    "test_corr = test_corr - tf.reduce_mean(test_corr, 1)\n",
    "new = sample_from_corr_matrix(test_corr, 8*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'resized_image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block1': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block2': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block3': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block4': tf.io.FixedLenFeature([], tf.string),\n",
    "\n",
    "    'music_spec': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_function(data):\n",
    "    parsed_data = tf.io.parse_single_example(data, feature_description)\n",
    "    \n",
    "    resized_image = tf.image.decode_jpeg(parsed_data[\"resized_image\"], channels = 3)\n",
    "    block1 = tf.io.parse_tensor(parsed_data[\"block1\"], tf.float16)\n",
    "    block2 = tf.io.parse_tensor(parsed_data[\"block2\"], tf.float16)\n",
    "    block3 = tf.io.parse_tensor(parsed_data[\"block3\"], tf.float16)\n",
    "    block4 = tf.io.parse_tensor(parsed_data[\"block4\"], tf.float16)\n",
    "    \n",
    "    music_spec = tf.io.parse_tensor(parsed_data[\"music_spec\"], tf.float16)\n",
    "    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dir = Path(os.getcwd()).parent  / \"data\" / \"tfrecords\" / \"train\"\n",
    "\n",
    "train_ds_files = tf.data.Dataset.list_files(str(training_data_dir / '*'), shuffle=True, seed=4321)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(train_ds_files, compression_type=\"GZIP\")\n",
    "train_ds = train_ds.shuffle(1024)\n",
    "train_ds = train_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.apply(tf.data.experimental.ignore_errors())\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# val_ds = tf.data.TFRecordDataset(str(val_data_path), compression_type=\"GZIP\")\n",
    "# val_ds = val_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.batch(BATCH_SIZE)\n",
    "# val_ds = val_ds.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.apply(tf.data.experimental.ignore_errors())\n",
    "# val_ds = val_ds.repeat()\n",
    "# val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# test_ds = tf.data.TFRecordDataset(str(test_data_path), compression_type=\"GZIP\")\n",
    "# test_ds = test_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "# test_ds = test_ds.batch(BATCH_SIZE)\n",
    "# test_ds = test_ds.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "# test_ds = test_ds.apply(tf.data.experimental.ignore_errors())\n",
    "# test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_7 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 32)                262176    \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 16)                8208      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 532,944\n",
      "Trainable params: 532,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tt = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((512, 16)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(32),\n",
    "\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(64),\n",
    "\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dense(128),\n",
    "\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dense(256),\n",
    "\n",
    "    tf.keras.layers.Dense(512),\n",
    "\n",
    "    tf.keras.layers.Dense(16),\n",
    "])\n",
    "\n",
    "tt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.2110682e+00, -2.6582247e-01, -6.8995088e-01, ...,\n",
       "        -9.3687675e-05, -7.0091186e-04,  7.4710237e-04],\n",
       "       [ 3.1946392e+00, -2.6211074e-01, -6.6866386e-01, ...,\n",
       "         3.7533202e-05, -7.6067663e-04, -1.0823988e-03],\n",
       "       [ 3.2044709e+00, -2.6437908e-01, -6.4931983e-01, ...,\n",
       "        -1.0651493e-03,  9.7554555e-04,  1.1246806e-03],\n",
       "       ...,\n",
       "       [ 7.9276795e+00, -1.2298405e+00, -5.1126796e-01, ...,\n",
       "        -3.3669829e-04,  3.4618980e-04, -3.6356723e-04],\n",
       "       [ 7.9331326e+00, -1.2008463e+00, -5.1423520e-01, ...,\n",
       "        -1.5075568e-05, -1.2177003e-03,  6.6069217e-04],\n",
       "       [ 7.9900341e+00, -1.2038032e+00, -5.1640689e-01, ...,\n",
       "        -1.0671059e-05,  6.8285607e-04, -3.3440182e-04]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.cast(tf.image.rgb_to_grayscale(test_img), tf.float32).numpy()[:, :, 0]\n",
    "pca = PCA()\n",
    "img_hat = pca.fit_transform(img)\n",
    "\n",
    "img_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9215800e-03, 3.9215772e-03, 3.9215754e-03, 3.9215754e-03,\n",
       "       3.9215754e-03, 3.9215744e-03, 3.9215735e-03, 3.9215735e-03,\n",
       "       3.9215735e-03, 3.9215735e-03, 3.9215735e-03, 3.9215735e-03,\n",
       "       3.9215735e-03, 3.9215735e-03, 3.9215726e-03, 3.9215726e-03,\n",
       "       3.9215726e-03, 3.9215726e-03, 3.9215726e-03, 3.9215726e-03,\n",
       "       3.9215726e-03, 3.9215726e-03, 3.9215726e-03, 3.9215726e-03,\n",
       "       3.9215726e-03, 3.9215717e-03, 3.9215717e-03, 3.9215717e-03,\n",
       "       3.9215717e-03, 3.9215717e-03, 3.9215717e-03, 3.9215717e-03,\n",
       "       3.9215717e-03, 3.9215717e-03, 3.9215717e-03, 3.9215717e-03,\n",
       "       3.9215717e-03, 3.9215717e-03, 3.9215707e-03, 3.9215707e-03,\n",
       "       3.9215707e-03, 3.9215707e-03, 3.9215707e-03, 3.9215707e-03,\n",
       "       3.9215707e-03, 3.9215707e-03, 3.9215707e-03, 3.9215707e-03,\n",
       "       3.9215707e-03, 3.9215707e-03, 3.9215707e-03, 3.9215707e-03,\n",
       "       3.9215707e-03, 3.9215707e-03, 3.9215707e-03, 3.9215707e-03,\n",
       "       3.9215707e-03, 3.9215707e-03, 3.9215707e-03, 3.9215707e-03,\n",
       "       3.9215707e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215698e-03, 3.9215698e-03,\n",
       "       3.9215698e-03, 3.9215698e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215689e-03, 3.9215689e-03,\n",
       "       3.9215689e-03, 3.9215689e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215679e-03, 3.9215679e-03,\n",
       "       3.9215679e-03, 3.9215679e-03, 3.9215675e-03, 3.9215675e-03,\n",
       "       3.9215675e-03, 3.9215675e-03, 3.9215675e-03, 3.9215675e-03,\n",
       "       3.9215675e-03, 3.9215675e-03, 3.9215675e-03, 3.9215675e-03,\n",
       "       3.9215675e-03, 3.9215675e-03, 3.9215675e-03, 3.9215675e-03,\n",
       "       3.9215670e-03, 3.9215670e-03, 3.9215670e-03, 3.9215670e-03,\n",
       "       3.9215670e-03, 3.9215670e-03, 3.9215670e-03, 3.9215665e-03,\n",
       "       3.9215665e-03, 3.9215665e-03, 3.9215665e-03, 3.9215665e-03,\n",
       "       3.9215665e-03, 3.9215665e-03, 3.9215665e-03, 3.9215665e-03,\n",
       "       3.9215661e-03, 3.9215661e-03, 3.9215656e-03, 3.9215656e-03,\n",
       "       3.9215651e-03, 3.9215651e-03, 3.9215651e-03, 3.9215647e-03,\n",
       "       3.9215647e-03, 3.9215642e-03, 3.9215642e-03, 3.9215642e-03,\n",
       "       3.9215637e-03, 3.9215633e-03, 3.9215623e-03, 3.9215619e-03,\n",
       "       3.9215614e-03, 3.9215600e-03, 3.9215600e-03, 4.6738780e-16],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.eye(256, 256).numpy()\n",
    "pca = PCA()\n",
    "test_hat = pca.fit_transform(test)\n",
    "pca.explained_variance_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
