{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, ReLU, Conv2D\n",
    "\n",
    "from tensorflow.nn import conv2d, conv2d_transpose\n",
    "from tensorflow.io import read_file\n",
    "from tensorflow.image import decode_image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv2d(x, kernel):\n",
    "    return conv2d(x, kernel, strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def _conv2d_transpose(x, kernel, output_shape):\n",
    "    return conv2d_transpose(\n",
    "            x, kernel,\n",
    "            output_shape=output_shape,\n",
    "            strides=[1, 2, 2, 1],\n",
    "            padding='SAME')\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = read_file(image_path)\n",
    "    image = decode_image(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletPooling(Layer):\n",
    "    \"\"\"\n",
    "    Wavelet Pooing Custom Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, name=''):\n",
    "        super(WaveletPooling, self).__init__()\n",
    "        self._name = name\n",
    "        square_of_2 = tf.math.sqrt(tf.constant(2, dtype=tf.float32))\n",
    "        L = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "        H = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[-1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "\n",
    "        self.LL = tf.reshape(tf.math.multiply(tf.transpose(L), L), (1, 2, 2, 1))\n",
    "        self.LH = tf.reshape(tf.math.multiply(tf.transpose(L), H), (1, 2, 2, 1))\n",
    "        self.HL = tf.reshape(tf.math.multiply(tf.transpose(H), L), (1, 2, 2, 1))\n",
    "        self.HH = tf.reshape(tf.math.multiply(tf.transpose(H), H), (1, 2, 2, 1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        LL, LH, HL, HH = self.repeat_filters(inputs.shape[-1])\n",
    "        return [_conv2d(inputs, LL),\n",
    "                _conv2d(inputs, LH),\n",
    "                _conv2d(inputs, HL),\n",
    "                _conv2d(inputs, HH)]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = (\n",
    "            input_shape[0], input_shape[1] // 2,\n",
    "            input_shape[2] // 2, input_shape[3]\n",
    "        )\n",
    "\n",
    "        return [shape, shape, shape, shape]\n",
    "\n",
    "    def repeat_filters(self, repeats):\n",
    "        # Can we optimize this?\n",
    "        return [\n",
    "            tf.transpose(tf.repeat(self.LL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.LH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HH, repeats, axis=0), (1, 2, 3, 0))\n",
    "        ]\n",
    "\n",
    "class WaveletUnpooling(Layer):\n",
    "    \"\"\"\n",
    "    Wavelet Unpooing Custom Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        super(WaveletUnpooling, self).__init__()\n",
    "        self._name = name\n",
    "        square_of_2 = tf.math.sqrt(tf.constant(2, dtype=tf.float32))\n",
    "        L = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "        H = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[-1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "\n",
    "        self.LL = tf.reshape(tf.math.multiply(tf.transpose(L), L), (1, 2, 2, 1))\n",
    "        self.LH = tf.reshape(tf.math.multiply(tf.transpose(L), H), (1, 2, 2, 1))\n",
    "        self.HL = tf.reshape(tf.math.multiply(tf.transpose(H), L), (1, 2, 2, 1))\n",
    "        self.HH = tf.reshape(tf.math.multiply(tf.transpose(H), H), (1, 2, 2, 1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        LL_in, LH_in, HL_in, HH_in, tensor_in = inputs\n",
    "        LL, LH, HL, HH = self.repeat_filters(LL_in.shape[-1])\n",
    "        out_shape = tf.shape(tensor_in)\n",
    "\n",
    "        return _conv2d_transpose(LL_in, LL, output_shape=out_shape) + _conv2d_transpose(LH_in, LH, output_shape=out_shape) + _conv2d_transpose(HL_in, HL, output_shape=out_shape) + _conv2d_transpose(HH_in, HH, output_shape=out_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        _ip_shape = input_shape[0]\n",
    "        shape = (\n",
    "            _ip_shape[0],\n",
    "            _ip_shape[1] * 2,\n",
    "            _ip_shape[2] * 2,\n",
    "            sum(ips[3] for ips in input_shape)\n",
    "        )\n",
    "\n",
    "        return shape\n",
    "\n",
    "    def repeat_filters(self, repeats):\n",
    "        # Can we optimize this?\n",
    "        return [\n",
    "            tf.transpose(tf.repeat(self.LL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.LH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "        ]\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [tf.keras.layers.InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        if s[1] == None:\n",
    "            return (None, None, None, s[3])\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad, h_pad = self.padding\n",
    "        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ReflectionPadding2D, self).get_config()\n",
    "        print(config)\n",
    "        return config\n",
    "\n",
    "class CNNBlock(Layer):\n",
    "    def __init__(self, filters, kernel, name):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self._name = name\n",
    "        \n",
    "        self.padding = ReflectionPadding2D()\n",
    "        self.conv2d = Conv2D(filters, kernel, padding = 'valid')\n",
    "        self.activation = ReLU()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.padding(inputs)\n",
    "        x = self.conv2d(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_feat(feat, center = False):\n",
    "    feat = tf.reshape(feat, (-1, feat.shape[-1]))\n",
    "    feat = tf.transpose(feat)\n",
    "    \n",
    "    feat_mean = tf.math.reduce_mean(feat, 1)\n",
    "    \n",
    "    if center:\n",
    "        feat_mean = tf.expand_dims(feat_mean, 1)\n",
    "        feat = tf.subtract(feat, feat_mean)\n",
    "        \n",
    "    return feat,feat_mean\n",
    "\n",
    "def center_feat(feat):\n",
    "    feat_mean = tf.math.reduce_mean(feat, 1)\n",
    "    feat_mean = tf.expand_dims(feat_mean, 1)\n",
    "    return tf.subtract(feat, feat_mean)\n",
    "\n",
    "def get_svd(feat):\n",
    "    feat = center_feat(feat)\n",
    "    feat = tf.matmul(feat, feat, transpose_b=True) / (feat.shape[1] - 1)\n",
    "    feat = feat + tf.eye(feat.shape[0])\n",
    "    \n",
    "    return tf.linalg.svd(feat)\n",
    "\n",
    "def get_style_correlation_transform(feat, return_mean = False):\n",
    "    feat, mean = preprocess_feat(feat)\n",
    "    s_e, _, s_v = get_svd(feat)\n",
    "    # The inverse of the content singular values matrix operation (^-0.5)\n",
    "    s_e = tf.pow(s_e, 0.5)\n",
    "    \n",
    "    EDE = tf.matmul(tf.matmul(s_v, tf.linalg.diag(s_e)), s_v, transpose_b=True)\n",
    "    return (EDE, mean) if return_mean else EDE\n",
    "\n",
    "def wct(content_feat_raw, style_feat_raw, alpha = 1):\n",
    "    style_EDE, style_mean = get_style_correlation_transform(style_feat_raw, return_mean = True)\n",
    "    content_feat, content_mean = preprocess_feat(content_feat_raw, center=True)\n",
    "    \n",
    "    c_e, _, c_v = get_svd(content_feat)\n",
    "    c_e = tf.pow(c_e, -0.5)\n",
    "    \n",
    "    content_EDE = tf.matmul(tf.matmul(c_v, tf.linalg.diag(c_e)), c_v, transpose_b=True)\n",
    "    content_whitened = tf.matmul(content_EDE, content_feat)\n",
    "\n",
    "    final_out = tf.matmul(style_EDE, content_whitened)\n",
    "    final_out = tf.add(final_out, tf.expand_dims(style_mean, 1))\n",
    "    final_out = tf.clip_by_value(\n",
    "        final_out,\n",
    "        tf.math.reduce_min(content_feat),\n",
    "        tf.math.reduce_max(content_feat),\n",
    "    )\n",
    "    \n",
    "    final_out = tf.reshape(tf.transpose(final_out), content_feat_raw.shape)\n",
    "    final_out = alpha * final_out + (1 - alpha) * content_feat_raw\n",
    "    return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletEncoder'\n",
    "        \n",
    "        self.preprocessing_conv2d = Conv2D(3, 1, padding = 'valid')\n",
    "        \n",
    "        ### Block 1\n",
    "        self.block1_conv2d_1 = CNNBlock(64, 3, 'WE_block1_conv2d_1')\n",
    "        self.block1_conv2d_2 = CNNBlock(64, 3, 'WE_block1_conv2d_2')\n",
    "        self.block1_pooling = WaveletPooling('WE_block1_pooling')\n",
    "        \n",
    "        ### Block 2\n",
    "        self.block2_conv2d_1 = CNNBlock(128, 3, 'WE_block2_conv2d_1')\n",
    "        self.block2_conv2d_2 = CNNBlock(128, 3, 'WE_block2_conv2d_2')\n",
    "        self.block2_pooling = WaveletPooling('WE_block2_pooling')\n",
    "        \n",
    "        ### Block 3\n",
    "        self.block3_conv2d_1 = CNNBlock(256, 3, 'WE_block3_conv2d_1')\n",
    "        self.block3_conv2d_2 = CNNBlock(256, 3, 'WE_block3_conv2d_2')\n",
    "        self.block3_conv2d_3 = CNNBlock(256, 3, 'WE_block3_conv2d_3')\n",
    "        self.block3_conv2d_4 = CNNBlock(256, 3, 'WE_block3_conv2d_4')\n",
    "        self.block3_pooling = WaveletPooling('WE_block3_pooling')\n",
    "        \n",
    "        ### Block 4\n",
    "        self.block4_conv2d_1 = CNNBlock(512, 3, 'WE_block4_conv2d_1')\n",
    "\n",
    "    def call(self, inputs, style_feat = None, trainable = False):\n",
    "        wavelet_skips = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None,\n",
    "        }\n",
    "        \n",
    "        features = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None\n",
    "        }\n",
    "        \n",
    "        x = self.preprocessing_conv2d(inputs)\n",
    "        \n",
    "        x = self.block1_conv2d_1(x)\n",
    "        x = self.block1_conv2d_2(x)\n",
    "        LL_1, LH_1, HL_1, HH_1 = self.block1_pooling(x)\n",
    "        wavelet_skips['block1'] = [LH_1, HL_1, HH_1, x]\n",
    "        features['block1'] = LL_1\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_1 = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (LL_1, style_feat['block1']),\n",
    "                dtype=LL_1.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block2_conv2d_1(LL_1)\n",
    "        x = self.block2_conv2d_2(x)\n",
    "        LL_2, LH_2, HL_2, HH_2 = self.block2_pooling(x)\n",
    "        wavelet_skips['block2'] = [LH_2, HL_2, HH_2, x]\n",
    "        features['block2'] = LL_2\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_2 = tf.map_fn(\n",
    "                lambda y: wct(y[0], y[1]),\n",
    "                (LL_2, style_feat['block2']),\n",
    "                dtype=LL_2.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block3_conv2d_1(LL_2)\n",
    "        x = self.block3_conv2d_2(x)\n",
    "        x = self.block3_conv2d_3(x)\n",
    "        x = self.block3_conv2d_4(x)\n",
    "        LL_3, LH_3, HL_3, HH_3 = self.block3_pooling(x)\n",
    "        wavelet_skips['block3'] = [LH_3, HL_3, HH_3, x]\n",
    "        features['block3'] = LL_3\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_3 = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (LL_3, style_feat['block3']),\n",
    "                dtype=LL_3.dtype\n",
    "            )\n",
    "        \n",
    "        x = self.block4_conv2d_1(LL_3)\n",
    "        features['block4'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block4']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        return x, wavelet_skips, features\n",
    "    \n",
    "class WaveletDecoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletDecoder'\n",
    "\n",
    "        ### Block 3\n",
    "        self.block3_conv2d_1 = CNNBlock(256, 3, 'WD_block4_conv2d_1')\n",
    "        self.block3_unpooling = WaveletUnpooling('WD_block4_unpooling')\n",
    "        self.block3_conv2d_2 = CNNBlock(256, 3, 'WD_block3_conv2d_2')\n",
    "        self.block3_conv2d_3 = CNNBlock(256, 3, 'WD_block3_conv2d_3')\n",
    "        self.block3_conv2d_4 = CNNBlock(256, 3, 'WD_block3_conv2d_4')\n",
    "\n",
    "        ### Block 2\n",
    "        self.block2_conv2d_1 = CNNBlock(128, 3, 'WE_block2_conv2d_1')\n",
    "        self.block2_unpooling = WaveletUnpooling('WE_block2_unpooling')\n",
    "        self.block2_conv2d_2 = CNNBlock(128, 3, 'WE_block2_conv2d_2')\n",
    "\n",
    "        ### Block 1\n",
    "        self.block1_conv2d_1 = CNNBlock(64, 3, 'WE_block1_conv2d_1')\n",
    "        self.block1_unpooling = WaveletUnpooling('WE_block1_unpooling')\n",
    "        self.block1_conv2d_2 = CNNBlock(64, 3, 'WE_block1_conv2d_2')\n",
    "\n",
    "        self.post_processing_padding = ReflectionPadding2D()\n",
    "        self.post_processing_conv2d = Conv2D(3, 3, padding = 'valid')\n",
    "\n",
    "    def call(self, inputs, skips, style_feat = None, trainable = False):\n",
    "        features = {\n",
    "            'block3': None,\n",
    "            'block2': None,\n",
    "            'block1': None,\n",
    "        }\n",
    "        \n",
    "        x = self.block3_conv2d_1(inputs)\n",
    "        x = self.block3_unpooling([x, *skips['block3']])\n",
    "        x = self.block3_conv2d_2(x)\n",
    "        x = self.block3_conv2d_3(x)\n",
    "        x = self.block3_conv2d_4(x)\n",
    "        features['block3'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block3']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "        \n",
    "        x = self.block2_conv2d_1(x)\n",
    "        x = self.block2_unpooling([x, *skips['block2']])\n",
    "        x = self.block2_conv2d_2(x)\n",
    "        features['block2'] = x\n",
    "\n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block2']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block1_conv2d_1(x)\n",
    "        x = self.block1_unpooling([x, *skips['block1']])\n",
    "        x = self.block1_conv2d_2(x)\n",
    "        features['block1'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block1']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.post_processing_padding(x)\n",
    "        x = self.post_processing_conv2d(x)\n",
    "\n",
    "        return x, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.post_processing_conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.post_processing_conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_2.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_3.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_3.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_4.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block3_conv2d_4.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block2_conv2d_2.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_1.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_1.conv2d.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_2.conv2d.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).decoder.block1_conv2d_2.conv2d.bias\n",
      "tf.Tensor(\n",
      "[[[[ 2.69911861e+00]\n",
      "   [ 4.70597565e-01]\n",
      "   [ 1.95553266e-02]\n",
      "   ...\n",
      "   [ 9.77831036e-02]\n",
      "   [ 9.70818847e-03]\n",
      "   [ 5.33213317e-01]]\n",
      "\n",
      "  [[ 4.70597625e-01]\n",
      "   [ 1.50200844e+00]\n",
      "   [ 9.08664688e-02]\n",
      "   ...\n",
      "   [ 3.87736410e-02]\n",
      "   [-1.31642804e-01]\n",
      "   [ 9.51277018e-02]]\n",
      "\n",
      "  [[ 1.95553340e-02]\n",
      "   [ 9.08664688e-02]\n",
      "   [ 1.34870195e+00]\n",
      "   ...\n",
      "   [-2.28688225e-01]\n",
      "   [-1.80304796e-03]\n",
      "   [-8.20220262e-03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 9.77831185e-02]\n",
      "   [ 3.87736373e-02]\n",
      "   [-2.28688151e-01]\n",
      "   ...\n",
      "   [ 1.51187348e+00]\n",
      "   [-5.32107092e-02]\n",
      "   [-4.85416502e-02]]\n",
      "\n",
      "  [[ 9.70818102e-03]\n",
      "   [-1.31642789e-01]\n",
      "   [-1.80304423e-03]\n",
      "   ...\n",
      "   [-5.32107092e-02]\n",
      "   [ 2.36675262e+00]\n",
      "   [ 1.16241835e-01]]\n",
      "\n",
      "  [[ 5.33213317e-01]\n",
      "   [ 9.51277018e-02]\n",
      "   [-8.20220262e-03]\n",
      "   ...\n",
      "   [-4.85416465e-02]\n",
      "   [ 1.16241820e-01]\n",
      "   [ 2.36061478e+00]]]], shape=(1, 64, 64, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\school\\imuse\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3348: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class WaveletAE(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletAE'\n",
    "        self.encoder = WaveletEncoder()\n",
    "        self.decoder = WaveletDecoder()\n",
    "        self.load_weights('../weights/wavelet_autoencoder')\n",
    "\n",
    "    def call(self, inputs, trainable = False):\n",
    "        x, skips, _ = self.encoder(inputs)\n",
    "        output, _ = self.decoder(x, skips)\n",
    "\n",
    "        return output\n",
    "        \n",
    "    def transfer(self, content_img, style_img, encoder_transfer = True, skips_transfer = True, decoder_transfer = True, alpha = 1):\n",
    "        style_features, style_skips = self.get_features(style_img)\n",
    "        x, content_skips, _ = self.encoder(content_img, style_features['encoder'] if encoder_transfer else None)\n",
    "        \n",
    "        if skips_transfer:\n",
    "            for key in content_skips.keys():\n",
    "                for i in range(3):\n",
    "                    content_skips[key][0] = tf.map_fn(\n",
    "                        lambda x: wct(x[0], x[1]),\n",
    "                        (content_skips[key][0], style_skips[key][0]),\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "                \n",
    "        out, _ = self.decoder(x, content_skips, style_features['decoder'] if decoder_transfer else None)\n",
    "        out = tf.clip_by_value(out, 0, 1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_features(self, inputs):\n",
    "        encoder_out, skips, encoder_feat = self.encoder(inputs)\n",
    "        _, decoder_feat = self.decoder(encoder_out, skips)\n",
    "        \n",
    "        features = {\n",
    "            'encoder': encoder_feat,\n",
    "            'decoder': decoder_feat,\n",
    "        }\n",
    "        \n",
    "        return features, skips\n",
    "    \n",
    "    def get_style_correlations(self, inputs, blocks = ['block1', 'block2', 'block3', 'block4'], ede=True):\n",
    "        _, _, encoder_feat = self.encoder(inputs)\n",
    "        correlations = []\n",
    "\n",
    "        def process_correlation(feature_map):\n",
    "            feat, _ = preprocess_feat(feature_map, center=True)\n",
    "            feat = tf.matmul(feat, feat, transpose_b=True) / (feat.shape[1] - 1)\n",
    "\n",
    "            return feat\n",
    "\n",
    "        for block in blocks:\n",
    "            corr = tf.map_fn(process_correlation if not ede else get_style_correlation_transform, encoder_feat[block])\n",
    "            corr = tf.expand_dims(corr, 3)\n",
    "            corr = tf.image.resize(corr, (corr.shape[1] // 2, corr.shape[2] // 2), 'nearest')\n",
    "            corr = tf.squeeze(corr, 3)\n",
    "            correlations.append(corr)\n",
    "\n",
    "        return correlations\n",
    "        \n",
    "test_img = tf.io.read_file('../assets/moli_content.jpg')\n",
    "test_img = tf.image.decode_image(test_img, dtype=tf.float16)\n",
    "\n",
    "test_img_style = tf.io.read_file('../assets/moli_style.jpg')\n",
    "test_img_style = tf.image.decode_image(test_img_style, dtype=tf.float16)\n",
    "\n",
    "wavelet_ae = WaveletAE()\n",
    "# r = wavelet_ae.transfer(tf.expand_dims(test_img, 0), tf.expand_dims(test_img_style, 0), skips_transfer=False, decoder_transfer=False)[0]\n",
    "# plt.imshow(r)\n",
    "wavelet_ae.get_style_correlations(tf.expand_dims(test_img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_corr_matrix(sigma, num_features = None, eigenvalues = None, eigenvectors = None):\n",
    "    data = tf.eye(sigma.shape[0], num_features)\n",
    "\n",
    "    if not eigenvectors or not eigenvectors:\n",
    "        eigenvalues, u, eigenvectors = tf.linalg.svd(sigma)\n",
    "        eigenvalues = tf.linalg.diag(eigenvalues)\n",
    "        \n",
    "    data = tf.matmul(tf.matmul(eigenvectors, tf.sqrt(eigenvalues)), data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'resized_image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block1': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block2': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block3': tf.io.FixedLenFeature([], tf.string),\n",
    "    'block4': tf.io.FixedLenFeature([], tf.string),\n",
    "\n",
    "    'music_spec': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_function(data):\n",
    "    parsed_data = tf.io.parse_single_example(data, feature_description)\n",
    "    \n",
    "    resized_image = tf.image.decode_jpeg(parsed_data[\"resized_image\"], channels = 3)\n",
    "    block1 = tf.io.parse_tensor(parsed_data[\"block1\"], tf.float16)\n",
    "    block2 = tf.io.parse_tensor(parsed_data[\"block2\"], tf.float16)\n",
    "    block3 = tf.io.parse_tensor(parsed_data[\"block3\"], tf.float16)\n",
    "    block4 = tf.io.parse_tensor(parsed_data[\"block4\"], tf.float16)\n",
    "    \n",
    "    music_spec = tf.io.parse_tensor(parsed_data[\"music_spec\"], tf.float16)\n",
    "    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dir = Path(os.getcwd()).parent  / \"data\" / \"tfrecords\" / \"train\"\n",
    "\n",
    "train_ds_files = tf.data.Dataset.list_files(str(training_data_dir / '*'), shuffle=True, seed=4321)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(train_ds_files, compression_type=\"GZIP\")\n",
    "train_ds = train_ds.shuffle(1024)\n",
    "train_ds = train_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.apply(tf.data.experimental.ignore_errors())\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# val_ds = tf.data.TFRecordDataset(str(val_data_path), compression_type=\"GZIP\")\n",
    "# val_ds = val_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.batch(BATCH_SIZE)\n",
    "# val_ds = val_ds.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.apply(tf.data.experimental.ignore_errors())\n",
    "# val_ds = val_ds.repeat()\n",
    "# val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# test_ds = tf.data.TFRecordDataset(str(test_data_path), compression_type=\"GZIP\")\n",
    "# test_ds = test_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "# test_ds = test_ds.batch(BATCH_SIZE)\n",
    "# test_ds = test_ds.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "# test_ds = test_ds.apply(tf.data.experimental.ignore_errors())\n",
    "# test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 77, 48, 3)\n",
      "(1, 77, 48, 3)\n",
      "(1, 77, 48, 3)\n",
      "(1, 77, 48, 3)\n",
      "(1, 77, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in train_ds.take(5):\n",
    "    print(i.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}