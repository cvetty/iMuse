{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, ReLU, Conv2D\n",
    "\n",
    "from tensorflow.nn import conv2d, conv2d_transpose\n",
    "from tensorflow.io import read_file\n",
    "from tensorflow.image import decode_image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv2d(x, kernel):\n",
    "    return conv2d(x, kernel, strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def _conv2d_transpose(x, kernel, output_shape):\n",
    "    return conv2d_transpose(\n",
    "            x, kernel,\n",
    "            output_shape=output_shape,\n",
    "            strides=[1, 2, 2, 1],\n",
    "            padding='SAME')\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = read_file(image_path)\n",
    "    image = decode_image(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletPooling(Layer):\n",
    "    \"\"\"\n",
    "    Wavelet Pooing Custom Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, name=''):\n",
    "        super(WaveletPooling, self).__init__()\n",
    "        self._name = name\n",
    "        square_of_2 = tf.math.sqrt(tf.constant(2, dtype=tf.float32))\n",
    "        L = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "        H = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[-1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "\n",
    "        self.LL = tf.reshape(tf.math.multiply(tf.transpose(L), L), (1, 2, 2, 1))\n",
    "        self.LH = tf.reshape(tf.math.multiply(tf.transpose(L), H), (1, 2, 2, 1))\n",
    "        self.HL = tf.reshape(tf.math.multiply(tf.transpose(H), L), (1, 2, 2, 1))\n",
    "        self.HH = tf.reshape(tf.math.multiply(tf.transpose(H), H), (1, 2, 2, 1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        LL, LH, HL, HH = self.repeat_filters(inputs.shape[-1])\n",
    "        return [_conv2d(inputs, LL),\n",
    "                _conv2d(inputs, LH),\n",
    "                _conv2d(inputs, HL),\n",
    "                _conv2d(inputs, HH)]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = (\n",
    "            input_shape[0], input_shape[1] // 2,\n",
    "            input_shape[2] // 2, input_shape[3]\n",
    "        )\n",
    "\n",
    "        return [shape, shape, shape, shape]\n",
    "\n",
    "    def repeat_filters(self, repeats):\n",
    "        # Can we optimize this?\n",
    "        return [\n",
    "            tf.transpose(tf.repeat(self.LL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.LH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HH, repeats, axis=0), (1, 2, 3, 0))\n",
    "        ]\n",
    "\n",
    "class WaveletUnpooling(Layer):\n",
    "    \"\"\"\n",
    "    Wavelet Unpooing Custom Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        super(WaveletUnpooling, self).__init__()\n",
    "        self._name = name\n",
    "        square_of_2 = tf.math.sqrt(tf.constant(2, dtype=tf.float32))\n",
    "        L = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "        H = tf.math.divide(\n",
    "            tf.constant(1, dtype=tf.float32),\n",
    "            tf.math.multiply(square_of_2, tf.constant([[-1, 1]], dtype=tf.float32))\n",
    "        )\n",
    "\n",
    "        self.LL = tf.reshape(tf.math.multiply(tf.transpose(L), L), (1, 2, 2, 1))\n",
    "        self.LH = tf.reshape(tf.math.multiply(tf.transpose(L), H), (1, 2, 2, 1))\n",
    "        self.HL = tf.reshape(tf.math.multiply(tf.transpose(H), L), (1, 2, 2, 1))\n",
    "        self.HH = tf.reshape(tf.math.multiply(tf.transpose(H), H), (1, 2, 2, 1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        LL_in, LH_in, HL_in, HH_in, tensor_in = inputs\n",
    "        LL, LH, HL, HH = self.repeat_filters(LL_in.shape[-1])\n",
    "        out_shape = tf.shape(tensor_in)\n",
    "\n",
    "        return _conv2d_transpose(LL_in, LL, output_shape=out_shape) + _conv2d_transpose(LH_in, LH, output_shape=out_shape) + _conv2d_transpose(HL_in, HL, output_shape=out_shape) + _conv2d_transpose(HH_in, HH, output_shape=out_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        _ip_shape = input_shape[0]\n",
    "        shape = (\n",
    "            _ip_shape[0],\n",
    "            _ip_shape[1] * 2,\n",
    "            _ip_shape[2] * 2,\n",
    "            sum(ips[3] for ips in input_shape)\n",
    "        )\n",
    "\n",
    "        return shape\n",
    "\n",
    "    def repeat_filters(self, repeats):\n",
    "        # Can we optimize this?\n",
    "        return [\n",
    "            tf.transpose(tf.repeat(self.LL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.LH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HL, repeats, axis=0), (1, 2, 3, 0)),\n",
    "            tf.transpose(tf.repeat(self.HH, repeats, axis=0), (1, 2, 3, 0)),\n",
    "        ]\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [tf.keras.layers.InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        if s[1] == None:\n",
    "            return (None, None, None, s[3])\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad, h_pad = self.padding\n",
    "        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ReflectionPadding2D, self).get_config()\n",
    "        print(config)\n",
    "        return config\n",
    "\n",
    "class CNNBlock(Layer):\n",
    "    def __init__(self, filters, kernel, name):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self._name = name\n",
    "        \n",
    "        self.padding = ReflectionPadding2D()\n",
    "        self.conv2d = Conv2D(filters, kernel, padding = 'valid')\n",
    "        self.activation = ReLU()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.padding(inputs)\n",
    "        x = self.conv2d(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_feat(feat, center = False):\n",
    "    feat = tf.reshape(feat, (-1, feat.shape[-1]))\n",
    "    feat = tf.transpose(feat)\n",
    "    \n",
    "    feat_mean = tf.math.reduce_mean(feat, 1)\n",
    "    \n",
    "    if center:\n",
    "        feat_mean = tf.expand_dims(feat_mean, 1)\n",
    "        feat = tf.subtract(feat, feat_mean)\n",
    "        \n",
    "    return feat,feat_mean\n",
    "\n",
    "def center_feat(feat):\n",
    "    feat_mean = tf.math.reduce_mean(feat, 1)\n",
    "    feat_mean = tf.expand_dims(feat_mean, 1)\n",
    "    return tf.subtract(feat, feat_mean)\n",
    "\n",
    "def get_svd(feat):\n",
    "    feat = center_feat(feat)\n",
    "    feat = tf.matmul(feat, feat, transpose_b=True) / (feat.shape[1] - 1)\n",
    "    feat = feat + tf.eye(feat.shape[0])\n",
    "    \n",
    "    return tf.linalg.svd(feat)\n",
    "\n",
    "def get_style_correlation_transform(feat, return_mean = False):\n",
    "    feat, mean = preprocess_feat(feat)\n",
    "    s_e, _, s_v = get_svd(feat)\n",
    "    # The inverse of the content singular values matrix operation (^-0.5)\n",
    "    s_e = tf.pow(s_e, 0.5)\n",
    "    \n",
    "    EDE = tf.matmul(tf.matmul(s_v, tf.linalg.diag(s_e)), s_v, transpose_b=True)\n",
    "    return (EDE, mean) if return_mean else EDE\n",
    "\n",
    "def wct(content_feat_raw, style_feat_raw, alpha = 1):\n",
    "    style_EDE, style_mean = get_style_correlation_transform(style_feat_raw, return_mean = True)\n",
    "    content_feat, content_mean = preprocess_feat(content_feat_raw, center=True)\n",
    "    \n",
    "    c_e, _, c_v = get_svd(content_feat)\n",
    "    c_e = tf.pow(c_e, -0.5)\n",
    "    \n",
    "    content_EDE = tf.matmul(tf.matmul(c_v, tf.linalg.diag(c_e)), c_v, transpose_b=True)\n",
    "    content_whitened = tf.matmul(content_EDE, content_feat)\n",
    "\n",
    "    final_out = tf.matmul(style_EDE, content_whitened)\n",
    "    final_out = tf.add(final_out, tf.expand_dims(style_mean, 1))\n",
    "    final_out = tf.clip_by_value(\n",
    "        final_out,\n",
    "        tf.math.reduce_min(content_feat),\n",
    "        tf.math.reduce_max(content_feat),\n",
    "    )\n",
    "    \n",
    "    final_out = tf.reshape(tf.transpose(final_out), content_feat_raw.shape)\n",
    "    final_out = alpha * final_out + (1 - alpha) * content_feat_raw\n",
    "    return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletEncoder'\n",
    "        \n",
    "        self.preprocessing_conv2d = Conv2D(3, 1, padding = 'valid')\n",
    "        \n",
    "        ### Block 1\n",
    "        self.block1_conv2d_1 = CNNBlock(64, 3, 'WE_block1_conv2d_1')\n",
    "        self.block1_conv2d_2 = CNNBlock(64, 3, 'WE_block1_conv2d_2')\n",
    "        self.block1_pooling = WaveletPooling('WE_block1_pooling')\n",
    "        \n",
    "        ### Block 2\n",
    "        self.block2_conv2d_1 = CNNBlock(128, 3, 'WE_block2_conv2d_1')\n",
    "        self.block2_conv2d_2 = CNNBlock(128, 3, 'WE_block2_conv2d_2')\n",
    "        self.block2_pooling = WaveletPooling('WE_block2_pooling')\n",
    "        \n",
    "        ### Block 3\n",
    "        self.block3_conv2d_1 = CNNBlock(256, 3, 'WE_block3_conv2d_1')\n",
    "        self.block3_conv2d_2 = CNNBlock(256, 3, 'WE_block3_conv2d_2')\n",
    "        self.block3_conv2d_3 = CNNBlock(256, 3, 'WE_block3_conv2d_3')\n",
    "        self.block3_conv2d_4 = CNNBlock(256, 3, 'WE_block3_conv2d_4')\n",
    "        self.block3_pooling = WaveletPooling('WE_block3_pooling')\n",
    "        \n",
    "        ### Block 4\n",
    "        self.block4_conv2d_1 = CNNBlock(512, 3, 'WE_block4_conv2d_1')\n",
    "\n",
    "    def call(self, inputs, style_feat = None, trainable = False):\n",
    "        wavelet_skips = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None,\n",
    "        }\n",
    "        \n",
    "        features = {\n",
    "            'block1': None,\n",
    "            'block2': None,\n",
    "            'block3': None\n",
    "        }\n",
    "        \n",
    "        x = self.preprocessing_conv2d(inputs)\n",
    "        \n",
    "        x = self.block1_conv2d_1(x)\n",
    "        x = self.block1_conv2d_2(x)\n",
    "        LL_1, LH_1, HL_1, HH_1 = self.block1_pooling(x)\n",
    "        wavelet_skips['block1'] = [LH_1, HL_1, HH_1, x]\n",
    "        features['block1'] = LL_1\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_1 = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (LL_1, style_feat['block1']),\n",
    "                dtype=LL_1.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block2_conv2d_1(LL_1)\n",
    "        x = self.block2_conv2d_2(x)\n",
    "        LL_2, LH_2, HL_2, HH_2 = self.block2_pooling(x)\n",
    "        wavelet_skips['block2'] = [LH_2, HL_2, HH_2, x]\n",
    "        features['block2'] = LL_2\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_2 = tf.map_fn(\n",
    "                lambda y: wct(y[0], y[1]),\n",
    "                (LL_2, style_feat['block2']),\n",
    "                dtype=LL_2.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block3_conv2d_1(LL_2)\n",
    "        x = self.block3_conv2d_2(x)\n",
    "        x = self.block3_conv2d_3(x)\n",
    "        x = self.block3_conv2d_4(x)\n",
    "        LL_3, LH_3, HL_3, HH_3 = self.block3_pooling(x)\n",
    "        wavelet_skips['block3'] = [LH_3, HL_3, HH_3, x]\n",
    "        features['block3'] = LL_3\n",
    "        \n",
    "        if style_feat:\n",
    "            LL_3 = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (LL_3, style_feat['block3']),\n",
    "                dtype=LL_3.dtype\n",
    "            )\n",
    "        \n",
    "        x = self.block4_conv2d_1(LL_3)\n",
    "        features['block4'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block4']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        return x, wavelet_skips, features\n",
    "    \n",
    "class WaveletDecoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletDecoder'\n",
    "\n",
    "        ### Block 3\n",
    "        self.block3_conv2d_1 = CNNBlock(256, 3, 'WD_block4_conv2d_1')\n",
    "        self.block3_unpooling = WaveletUnpooling('WD_block4_unpooling')\n",
    "        self.block3_conv2d_2 = CNNBlock(256, 3, 'WD_block3_conv2d_2')\n",
    "        self.block3_conv2d_3 = CNNBlock(256, 3, 'WD_block3_conv2d_3')\n",
    "        self.block3_conv2d_4 = CNNBlock(256, 3, 'WD_block3_conv2d_4')\n",
    "\n",
    "        ### Block 2\n",
    "        self.block2_conv2d_1 = CNNBlock(128, 3, 'WE_block2_conv2d_1')\n",
    "        self.block2_unpooling = WaveletUnpooling('WE_block2_unpooling')\n",
    "        self.block2_conv2d_2 = CNNBlock(128, 3, 'WE_block2_conv2d_2')\n",
    "\n",
    "        ### Block 1\n",
    "        self.block1_conv2d_1 = CNNBlock(64, 3, 'WE_block1_conv2d_1')\n",
    "        self.block1_unpooling = WaveletUnpooling('WE_block1_unpooling')\n",
    "        self.block1_conv2d_2 = CNNBlock(64, 3, 'WE_block1_conv2d_2')\n",
    "\n",
    "        self.post_processing_padding = ReflectionPadding2D()\n",
    "        self.post_processing_conv2d = Conv2D(3, 3, padding = 'valid')\n",
    "\n",
    "    def call(self, inputs, skips, style_feat = None, trainable = False):\n",
    "        features = {\n",
    "            'block3': None,\n",
    "            'block2': None,\n",
    "            'block1': None,\n",
    "        }\n",
    "        \n",
    "        x = self.block3_conv2d_1(inputs)\n",
    "        x = self.block3_unpooling([x, *skips['block3']])\n",
    "        x = self.block3_conv2d_2(x)\n",
    "        x = self.block3_conv2d_3(x)\n",
    "        x = self.block3_conv2d_4(x)\n",
    "        features['block3'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block3']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "        \n",
    "        x = self.block2_conv2d_1(x)\n",
    "        x = self.block2_unpooling([x, *skips['block2']])\n",
    "        x = self.block2_conv2d_2(x)\n",
    "        features['block2'] = x\n",
    "\n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block2']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.block1_conv2d_1(x)\n",
    "        x = self.block1_unpooling([x, *skips['block1']])\n",
    "        x = self.block1_conv2d_2(x)\n",
    "        features['block1'] = x\n",
    "        \n",
    "        if style_feat:\n",
    "            x = tf.map_fn(\n",
    "                lambda x: wct(x[0], x[1]),\n",
    "                (x, style_feat['block1']),\n",
    "                dtype=x.dtype\n",
    "            )\n",
    "            \n",
    "        x = self.post_processing_padding(x)\n",
    "        x = self.post_processing_conv2d(x)\n",
    "\n",
    "        return x, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletAE(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._name = 'WaveletAE'\n",
    "        self.encoder = WaveletEncoder()\n",
    "        self.decoder = WaveletDecoder()\n",
    "        self.load_weights('../weights/wavelet_autoencoder')\n",
    "\n",
    "    def call(self, inputs, trainable = False):\n",
    "        x, skips, _ = self.encoder(inputs)\n",
    "        output, _ = self.decoder(x, skips)\n",
    "\n",
    "        return output\n",
    "        \n",
    "    def transfer(self, content_img, style_img, encoder_transfer = True, skips_transfer = True, decoder_transfer = True, alpha = 1):\n",
    "        style_features, style_skips = self.get_features(style_img)\n",
    "        x, content_skips, _ = self.encoder(content_img, style_features['encoder'] if encoder_transfer else None)\n",
    "        \n",
    "        if skips_transfer:\n",
    "            for key in content_skips.keys():\n",
    "                for i in range(3):\n",
    "                    content_skips[key][0] = tf.map_fn(\n",
    "                        lambda x: wct(x[0], x[1]),\n",
    "                        (content_skips[key][0], style_skips[key][0]),\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "                \n",
    "        out, _ = self.decoder(x, content_skips, style_features['decoder'] if decoder_transfer else None)\n",
    "        out = tf.clip_by_value(out, 0, 1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_features(self, inputs):\n",
    "        encoder_out, skips, encoder_feat = self.encoder(inputs)\n",
    "        _, decoder_feat = self.decoder(encoder_out, skips)\n",
    "        \n",
    "        features = {\n",
    "            'encoder': encoder_feat,\n",
    "            'decoder': decoder_feat,\n",
    "        }\n",
    "        \n",
    "        return features, skips\n",
    "        \n",
    "test_img = tf.io.read_file('../assets/moli_content.jpg')\n",
    "test_img = tf.image.decode_image(test_img, dtype=tf.float16)\n",
    "\n",
    "test_img_style = tf.io.read_file('../assets/moli_style.jpg')\n",
    "test_img_style = tf.image.decode_image(test_img_style, dtype=tf.float16)\n",
    "\n",
    "wavelet_ae = WaveletAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_corr_matrix(sigma, num_features = None, eigenvalues = None, eigenvectors = None):\n",
    "    data = tf.eye(sigma.shape[0], num_features)\n",
    "\n",
    "    if not eigenvectors or not eigenvectors:\n",
    "        eigenvalues, u, eigenvectors = tf.linalg.svd(sigma)\n",
    "        eigenvalues = tf.linalg.diag(eigenvalues)\n",
    "        \n",
    "    data = tf.matmul(tf.matmul(eigenvectors, tf.sqrt(eigenvalues)), data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0.81814516, 0.67093635, 0.9114053 , 0.01255274, 0.60665643,\n",
       "        0.87863755, 0.10737753, 0.61788845, 0.7887709 , 0.37638962],\n",
       "       [0.5569432 , 0.9119735 , 0.03203976, 0.64768994, 0.6504371 ,\n",
       "        0.88924754, 0.9991813 , 0.8690746 , 0.06949031, 0.91188097],\n",
       "       [0.16054773, 0.8682692 , 0.3797729 , 0.19993234, 0.7577106 ,\n",
       "        0.02513528, 0.2583996 , 0.10814404, 0.48027182, 0.11917496],\n",
       "       [0.41369414, 0.7429981 , 0.9240122 , 0.60481   , 0.08651209,\n",
       "        0.9741082 , 0.7406219 , 0.27923965, 0.08161557, 0.8272071 ],\n",
       "       [0.79215777, 0.37163877, 0.20451856, 0.8862821 , 0.5812131 ,\n",
       "        0.9042901 , 0.22144556, 0.0365181 , 0.86242425, 0.20869052],\n",
       "       [0.7541809 , 0.63204896, 0.731931  , 0.5966114 , 0.38791597,\n",
       "        0.07000744, 0.1448189 , 0.1772914 , 0.37726223, 0.93862474],\n",
       "       [0.9329052 , 0.03799462, 0.01893723, 0.17572784, 0.29898608,\n",
       "        0.26945972, 0.94430697, 0.03457725, 0.98951364, 0.41682506],\n",
       "       [0.21593976, 0.27871454, 0.3706603 , 0.92520094, 0.46735   ,\n",
       "        0.4296993 , 0.43112195, 0.41571498, 0.07604182, 0.8097793 ],\n",
       "       [0.27852404, 0.28335106, 0.3850534 , 0.21313584, 0.64260375,\n",
       "        0.07209659, 0.5459994 , 0.46617186, 0.92544556, 0.38693643],\n",
       "       [0.89651334, 0.90334296, 0.7178066 , 0.62212217, 0.4020239 ,\n",
       "        0.32445824, 0.5460712 , 0.3598646 , 0.7019564 , 0.42212343]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.random.uniform((10, 10))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[5.1148043, 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 1.6161581, 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 1.2747265, 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 1.0543399, 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.9879097, 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e, u, v = tf.linalg.svd(test)\n",
    "e = pad_sequences(tf.expand_dims(e[:5], 0), maxlen=e.shape[0], padding='post', dtype='float32')[0]\n",
    "e = tf.linalg.diag(e)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[ 0.7414155 ,  0.8422563 ,  0.865973  ,  0.14717644,  0.6085492 ,\n",
       "         0.89890456,  0.1602135 ,  0.4680623 ,  0.80021733,  0.21415482],\n",
       "       [ 0.40664363,  0.8301804 ,  0.15668148,  0.6551702 ,  0.65002227,\n",
       "         0.91718006,  1.0986443 ,  0.8425497 ,  0.12763266,  0.89500344],\n",
       "       [ 0.26298672,  0.6851393 ,  0.4660395 ,  0.04865327,  0.60821164,\n",
       "        -0.04073204,  0.24273486,  0.3852963 ,  0.5010355 ,  0.2695733 ],\n",
       "       [ 0.5419282 ,  0.7246532 ,  0.7124187 ,  0.77587014,  0.2714573 ,\n",
       "         0.95961887,  0.43242183,  0.43172425,  0.02956969,  0.8205058 ],\n",
       "       [ 0.92853206,  0.26814646,  0.40736395,  0.535882  ,  0.310881  ,\n",
       "         0.833755  ,  0.45031723,  0.12816715,  0.83230746,  0.36940756],\n",
       "       [ 0.6008828 ,  0.64543796,  0.8199284 ,  0.72891223,  0.37951854,\n",
       "         0.08356208,  0.2536218 ,  0.13174513,  0.42454335,  0.7783868 ],\n",
       "       [ 0.8344478 ,  0.03990941, -0.09182064,  0.4330673 ,  0.44778135,\n",
       "         0.29750976,  0.76559806,  0.09025875,  1.0372815 ,  0.3141196 ],\n",
       "       [ 0.37193117,  0.48291865,  0.3453782 ,  0.75092745,  0.25933337,\n",
       "         0.38656443,  0.57110476,  0.30111396,  0.0186416 ,  0.8210091 ],\n",
       "       [ 0.4989796 ,  0.50311357,  0.23642012,  0.18843256,  0.6472579 ,\n",
       "         0.03944242,  0.53216624,  0.33439443,  0.7867308 ,  0.31793016],\n",
       "       [ 0.7678375 ,  0.7277707 ,  0.73050016,  0.5602534 ,  0.5906016 ,\n",
       "         0.4092013 ,  0.4387455 ,  0.3214828 ,  0.7551935 ,  0.6229932 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.matmul(u, e), v, transpose_b=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}